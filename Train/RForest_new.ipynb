{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0838ac-54b8-4f84-85f0-c0a44a3f351c",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a37e350-9f25-43ee-a37c-86e2194a7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db50f8e-06ff-4fb0-a584-bbd8c103f704",
   "metadata": {},
   "source": [
    "## (1) Random Forest\n",
    "\n",
    "+ 重要参数:\n",
    "  1. n_estimators: \n",
    "  2. max_depth\n",
    "  3. max_features\n",
    "  4. min_samples_split\n",
    "  5. min_samples_leaf\n",
    "  6. bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8a82886-6c49-4703-be86-45be8eb831b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix    #导入计算混淆矩阵的包\n",
    "def specificity_score(y_true, y_pred):\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    TP = C[1,1]\n",
    "    FP = C[0,1]\n",
    "    TN = C[0,0]\n",
    "    FN = C[1,0]\n",
    "    specificity = TN/(TN+FP)\n",
    "    return specificity\n",
    "\n",
    "def classification_evaluation(y_true, y_pred, y_score):\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_true, y_score)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    specificity = specificity_score(y_true, y_pred)\n",
    "    evaluation = {'accuracy':accuracy, 'recall':recall, 'precision':precision, 'f1':f1, 'auc':auc, 'specificity':specificity}\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f15fab-af4b-4c96-a1d8-8dde733f967c",
   "metadata": {},
   "source": [
    "### Global params setting and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c8e83700-f1c0-4340-ac8c-cf7cfaa1f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "traindir = '../Feature_filter/Feas_data'\n",
    "testdir = '../Feature_filter/Feas_data_test'\n",
    "imgdir = os.path.join(cwd, 'IMG')\n",
    "modeldir = os.path.join(cwd, 'Model')\n",
    "tag_cols = ['pid', 'label', 'series', 'image', 'mask']\n",
    "sequence_id = [2, 3, 4]\n",
    "# Generate the random seed\n",
    "random_state = random.randint(1,10000)\n",
    "\n",
    "# Load the SSM features.\n",
    "SSM_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]\n",
    "SSM_test_slist = [pd.read_excel(os.path.join(testdir, 'SSM_test.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a1cb9e-a623-4388-87ee-4a2d18c2abd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pid', 'label', 'series', 'image', 'mask', 'glszm_SmallAreaEmphasis_logarithm', 'glcm_InverseVariance_exponential', 'glszm_GrayLevelNonUniformity_wavelet-HHH', 'firstorder_Skewness_logarithm', 'glcm_Correlation_log-sigma-3-0-mm-3D']\n",
      "['pid', 'label', 'series', 'image', 'mask', 'gldm_DependenceVariance_wavelet-LLH', 'ngtdm_Contrast_wavelet-HHL', 'firstorder_Skewness_log-sigma-2-0-mm-3D', 'glcm_Imc2_wavelet-HHH', 'glrlm_RunEntropy_exponential']\n",
      "['pid', 'label', 'series', 'image', 'mask', 'glrlm_ShortRunLowGrayLevelEmphasis_square', 'glszm_ZoneEntropy_exponential']\n",
      "6 6 3\n"
     ]
    }
   ],
   "source": [
    "# Print features\n",
    "SSM_features_list = [df.columns for df in SSM_train_slist]\n",
    "print(SSM_features_list[0].to_list())\n",
    "print(SSM_features_list[1].to_list())\n",
    "print(SSM_features_list[2].to_list())\n",
    "print(len(SSM_features_list[0])-4, len(SSM_features_list[1])-4, len(SSM_features_list[2])-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3768fc6b-986f-429f-b938-e1a25ff91e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "SSM_train_slist = [df.sample(frac=1.0, random_state=random_state) for df in SSM_train_slist]\n",
    "SSM_train_y = [df['label'] for df in SSM_train_slist]\n",
    "ssm_train_pid = SSM_train_slist[0]['pid']\n",
    "SSM_train_x = [df.drop(tag_cols, axis=1) for df in SSM_train_slist]\n",
    "SSM_train_x = [standardscaler.fit_transform(df) for df in SSM_train_x]\n",
    "# Test data\n",
    "SSM_test_slist = [df.sample(frac=1.0, random_state=random_state) for df in SSM_test_slist]\n",
    "SSM_test_y = [df['label'] for df in SSM_test_slist]\n",
    "ssm_test_pid = SSM_test_slist[0]['pid']\n",
    "SSM_test_x = [df.drop(tag_cols, axis=1) for df in SSM_test_slist]\n",
    "SSM_test_x = [standardscaler.fit_transform(df) for df in SSM_test_x]\n",
    "\n",
    "SSM2_train_y, SSM3_train_y, SSM4_train_y = (y_.to_list() for y_ in SSM_train_y)             \n",
    "SSM2_train_x, SSM3_train_x, SSM4_train_x = (x_ for x_ in SSM_train_x)\n",
    "SSM2_test_y, SSM3_test_y, SSM4_test_y = (y_.to_list() for y_ in SSM_test_y)\n",
    "SSM2_test_x, SSM3_test_x, SSM4_test_x = (x_ for x_ in SSM_test_x)\n",
    "SSM2_model, SSM3_model, SSM4_model = (f'RandomForest_SSM{i+2}.model' for i in range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedf637-cdd3-48a6-b19c-cac679fff0d1",
   "metadata": {},
   "source": [
    "### 随机森林系统调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab93fb-6af0-4857-84ce-91772a6391a1",
   "metadata": {},
   "source": [
    "### SSM2\n",
    "#### Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49942c7-2803-45e8-9a80-c69d5b03424d",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优\n",
    "+ 按照排列组合来计算的话，会有很多很多种组合方式，如果要一一尝试未免也太麻烦了。因此，我们用到RandomizedSearchCV这一功能——其将随机匹配每一种超参数组合，并输出最优的组合。换句话说，我们用RandomizedSearchCV来进行随机的排列，而不是对所有的超参数排列组合方法进行遍历。这样子确实可以节省很多时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade62c72-b763-412e-ba05-0688ddfa28df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20188/3662809037.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                    )\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSSM2_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSSM2_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbest_hp_now\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=3,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433a93b-aede-48ba-8a1d-b3e5d928631f",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3023fcb7-7373-47d2-8893-b6e38daba533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[900, 1100, 1200],\n",
    "                          'max_features':[2, 3, 4],\n",
    "                          'max_depth':[300, 490, 600],\n",
    "                          'min_samples_split':[2, 3, 4], # Greater than 1\n",
    "                          'min_samples_leaf':[6, 8, 10]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277b20bd-2a7c-4368-8040-21280fd8df95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[700,800],\n",
    "                          'max_features':[2],\n",
    "                          'max_depth':[400,500],\n",
    "                          'min_samples_split':[3], # Greater than 1\n",
    "                          'min_samples_leaf':[12, 13]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=6,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                              scoring='accuracy'\n",
    "                                              )\n",
    "random_forest_model_test_3_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e8fae-f66a-40f3-aeb4-ab6616a87b12",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1b276be-30f1-4669-99fb-8e13c5f92073",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_forest_model_test_3_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26910/3040880100.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build RF regression model with optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSSM2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_3_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Predict test set data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_forest_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSSM2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSSM2_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSM2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSSM2_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSSM2_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_forest_model_test_3_random' is not defined"
     ]
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM2=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM2.predict(SSM2_test_x)\n",
    "score = SSM2.score(SSM2_test_x, SSM2_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM2, os.path.join(modeldir, SSM2_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc0005-8108-4cb9-92c2-4276d0370c16",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c578804e-72cd-46c5-b98d-84ea8d861ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7721518987341772,\n",
       " 'recall': 0.9029126213592233,\n",
       " 'precision': 0.7815126050420168,\n",
       " 'f1': 0.8378378378378379,\n",
       " 'auc': 0.853486319505737,\n",
       " 'specificity': 0.5272727272727272}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM2_model)) \n",
    "predict_label = model_forest.predict(SSM2_train_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM2_train_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM2_train_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_train_pid, 'dataset':'train', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "441f2f38-29ee-42a7-bec8-3ac059975e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7285714285714285,\n",
       " 'recall': 0.9347826086956522,\n",
       " 'precision': 0.7288135593220338,\n",
       " 'f1': 0.819047619047619,\n",
       " 'auc': 0.6567028985507246,\n",
       " 'specificity': 0.3333333333333333}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM2_model)) \n",
    "predict_label = model_forest.predict(SSM2_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM2_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM2_test_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_test_pid, 'dataset':'test', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "test_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "535fe554-fda1-4ab9-b2a3-d84449129e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm2_df = pd.concat([train_df, test_df])\n",
    "ssm2_df.to_csv('./radiomics_result_20230406/ssm2.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97235b70-eeea-44fc-ab32-6f6436112f83",
   "metadata": {},
   "source": [
    "### SSM3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746bf5e8-fee0-419b-8232-e02fcd83a636",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d30a2ccc-4211-4e7d-bc49-4161761192fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4b912-82c3-4e24-a141-8bf3d62d724c",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c355302-ead1-4afd-a26e-0c54d48dadcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[400,450,500],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[100, 120, 200],\n",
    "                          'min_samples_split':[4,5,8], # Greater than 1\n",
    "                          'min_samples_leaf':[1,2]\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1)\n",
    "random_forest_model_test_2_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f6aede5-8f98-4e91-8d3b-0f62b9751e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[1600],\n",
    "                          'max_features':[4,5],\n",
    "                          'max_depth':[200, 210],\n",
    "                          'min_samples_split':[2], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_3_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd346ab1-6c8e-47fe-ab8c-4d4613692292",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dbf0cc4b-f519-4cfe-9ae1-a6194d29beb1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'random_forest_model_test_3_random' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_26910/2659832753.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Build RF regression model with optimal hyperparameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mSSM3\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_3_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;31m# Predict test set data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mrandom_forest_predict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mSSM3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSSM3_test_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSSM3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSSM3_test_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mSSM3_test_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'random_forest_model_test_3_random' is not defined"
     ]
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM3=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM3.predict(SSM3_test_x)\n",
    "score = SSM3.score(SSM3_test_x, SSM3_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM3, os.path.join(modeldir, SSM3_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84058010-afca-4dc1-b760-2ba723495f3a",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68d31570-cdfd-48fb-971f-0c6f9ff640f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8227848101265823,\n",
       " 'recall': 0.9514563106796117,\n",
       " 'precision': 0.8099173553719008,\n",
       " 'f1': 0.8749999999999999,\n",
       " 'auc': 0.9353927625772286,\n",
       " 'specificity': 0.5818181818181818}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM3_model))\n",
    "predict_label = model_forest.predict(SSM3_train_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM3_train_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM3_train_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_train_pid, 'dataset':'train', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1504aed5-3a5e-43b8-9eb5-b00ecc497107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7,\n",
       " 'recall': 0.8695652173913043,\n",
       " 'precision': 0.7272727272727273,\n",
       " 'f1': 0.792079207920792,\n",
       " 'auc': 0.6639492753623188,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM3_model))\n",
    "predict_label = model_forest.predict(SSM3_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM3_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM3_test_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_test_pid, 'dataset':'test', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "test_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2b042a9f-a01b-450c-b5ed-3057fed16fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm3_df = pd.concat([train_df, test_df])\n",
    "ssm3_df.to_csv('./radiomics_result_20230406/ssm3.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4055b8-456e-4499-9084-d9c83b28c8fc",
   "metadata": {},
   "source": [
    "### SSM4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e740d8e-4e6f-4ad3-adb3-785fb5427b2a",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优\n",
    "+ 按照排列组合来计算的话，会有很多很多种组合方式，如果要一一尝试未免也太麻烦了。因此，我们用到RandomizedSearchCV这一功能——其将随机匹配每一种超参数组合，并输出最优的组合。换句话说，我们用RandomizedSearchCV来进行随机的排列，而不是对所有的超参数排列组合方法进行遍历。这样子确实可以节省很多时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66b9f522-8669-49a9-b79b-20c382887b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66807b0d-3564-4ea9-9adf-4b3e5ec750f8",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c22f27-22c7-4915-b949-837fa210f02c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[2500, 2750],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[300,400,500],\n",
    "                          'min_samples_split':[8,10,12], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8,12]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8fdee37-d6fa-4991-a06b-095851f1147d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[2500],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[400],\n",
    "                          'min_samples_split':[8], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='accuracy')\n",
    "random_forest_model_test_3_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b09cb-702c-465d-8a52-2a8a0b2ea2ee",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ac1212-e511-44f7-88bb-4f1faabbee71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM4=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM4.predict(SSM4_test_x)\n",
    "score = SSM4.score(SSM4_test_x, SSM4_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM4, os.path.join(modeldir, SSM4_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01208cc-7ebd-4744-aed2-53b4705fa8bd",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4ba4d5b6-e125-4962-8db7-c2d7f0555705",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7341772151898734,\n",
       " 'recall': 0.9029126213592233,\n",
       " 'precision': 0.744,\n",
       " 'f1': 0.8157894736842106,\n",
       " 'auc': 0.8317740511915269,\n",
       " 'specificity': 0.41818181818181815}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM4_model)) \n",
    "predict_label = model_forest.predict(SSM4_train_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM4_train_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM4_train_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_train_pid, 'dataset':'train', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d256bab7-c8e5-43e5-86b8-d3bcdbba3e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7428571428571429,\n",
       " 'recall': 0.9347826086956522,\n",
       " 'precision': 0.7413793103448276,\n",
       " 'f1': 0.826923076923077,\n",
       " 'auc': 0.7001811594202899,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM4_model)) \n",
    "predict_label = model_forest.predict(SSM4_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM4_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM4_test_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':ssm_test_pid, 'dataset':'test', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "test_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fdd360dd-1c58-4ac2-bc21-4252446caf20",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssm4_df = pd.concat([train_df, test_df])\n",
    "ssm4_df.to_csv('./radiomics_result_20230406/ssm4.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d60db2-1d01-4d30-9385-5e71dfbcf695",
   "metadata": {},
   "source": [
    "### DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b416aeae-c2e4-4b2b-99a8-0a6b6606d9d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i91', 'i76', 'i4', 'i124', 'i20', 'i120', 'i25', 'i165', 'i167', 'i219', 'i78', 'i59', 'i215', 'i162', 'i42', 'i118', 'i176', 'i116', 'i101', 'i161', 'i186', 'i86', 'i144', 'i151', 'i72', 'i190', 'i234', 'i198', 'i139', 'i64', 'i82', 'i196', 'i183', 'i156', 'i149', 'i11', 'i84', 'i99', 'i131', 'i71', 'i226', 'i10', 'i50', 'i193', 'i92', 'i35', 'i93', 'i29', 'i199', 'i85', 'i106', 'i200', 'i80', 'i111', 'i230', 'i170', 'i14', 'i39', 'i191', 'i184', 'i164', 'i229', 'i53', 'i49', 'i107', 'i58', 'i206', 'i95', 'i188', 'i45', 'i13', 'i227', 'i34', 'i52', 'i8', 'i70', 'i171', 'i54', 'i22', 'i9', 'i135', 'i160', 'i228', 'i147', 'i102', 'i148', 'i46', 'i113', 'i159', 'i195', 'i112', 'i231', 'i2', 'i16', 'i209', 'i32', 'i163', 'i36', 'i205', 'i175', 'i189', 'i174', 'i15', 'i69', 'i197', 'i179', 'i178', 'i18', 'i152', 'i143', 'i220', 'i109', 'i150', 'i203', 'i77', 'i97', 'i137', 'i44', 'i40', 'i81', 'i61', 'i169', 'i31', 'i211', 'i104', 'i1', 'i142', 'i154', 'i202', 'i140', 'i12', 'i3', 'i155', 'i27', 'i94', 'i74', 'i216', 'i121', 'i138', 'i134', 'i235', 'i194', 'i119', 'i153', 'i192', 'i212', 'i201', 'i180', 'i28', 'i65', 'i23', 'i130', 'i37', 'i26', 'i63', 'i47', 'i38', 'i141']\n",
      "['i5', 'i6', 'i7', 'i17', 'i19', 'i21', 'i24', 'i30', 'i33', 'i41', 'i43', 'i48', 'i55', 'i56', 'i57', 'i60', 'i62', 'i66', 'i67', 'i68', 'i73', 'i75', 'i79', 'i83', 'i87', 'i88', 'i89', 'i90', 'i96', 'i100', 'i103', 'i105', 'i108', 'i110', 'i115', 'i117', 'i126', 'i127', 'i128', 'i129', 'i133', 'i136', 'i145', 'i146', 'i157', 'i158', 'i166', 'i168', 'i172', 'i173', 'i177', 'i181', 'i182', 'i185', 'i187', 'i204', 'i207', 'i208', 'i210', 'i213', 'i214', 'i217', 'i218', 'i221', 'i222', 'i223', 'i224', 'i225', 'i232', 'i233']\n"
     ]
    }
   ],
   "source": [
    "# Load the DSM features.\n",
    "Dtag_cols = ['pid', 'label']\n",
    "DSM_train_slist = [pd.read_excel(os.path.join(traindir, 'DSM_feas_mrmr_sel.xlsx'), sheet_name=f'no_sequence{num}') for num in sequence_id]\n",
    "DSM_train3 = DSM_train_slist[1]\n",
    "DSM_test_slist = [pd.read_excel(os.path.join(testdir, 'DSM_test.xlsx'), sheet_name=f'no_sequence{num}') for num in sequence_id]\n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "DSM_train_slist = [df.sample(frac=1.0, random_state=random_state) for df in DSM_train_slist]\n",
    "DSM_train_y = [df['label'] for df in DSM_train_slist]\n",
    "DSM_train_x = [df.drop(Dtag_cols, axis=1) for df in DSM_train_slist]\n",
    "train_pid = list(DSM_train_slist[0]['pid'].apply(lambda x: 'i'+str(x)))\n",
    "print(train_pid)\n",
    "#DSM_train_x = [standardscaler.fit_transform(df) for df in DSM_train_x]\n",
    "# Test data\n",
    "#DSM_test_slist = [df.sample(frac=1.0, random_state=random_state) for df in DSM_test_slist]\n",
    "DSM_test_y = [df['label'] for df in DSM_test_slist]\n",
    "DSM_test_x = [df.drop(Dtag_cols, axis=1) for df in DSM_test_slist]\n",
    "test_pid = list(DSM_test_slist[0]['pid'].apply(lambda x: 'i'+str(x)))\n",
    "print(test_pid)\n",
    "#DSM_test_x = [standardscaler.fit_transform(df) for df in DSM_test_x]\n",
    "\n",
    "DSM2_train_y, DSM3_train_y, DSM4_train_y = (y_.to_list() for y_ in DSM_train_y)             \n",
    "DSM2_train_x, DSM3_train_x, DSM4_train_x = (np.array(x_) for x_ in DSM_train_x)\n",
    "DSM2_test_y, DSM3_test_y, DSM4_test_y = (y_.to_list() for y_ in DSM_test_y)\n",
    "DSM2_test_x, DSM3_test_x, DSM4_test_x = (np.array(x_) for x_ in DSM_test_x)\n",
    "DSM2_model, DSM3_model, DSM4_model = (f'RandomForest_DSM{i+2}.model' for i in range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9f337d76-5b14-4756-b170-62e6e3be18fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pid', 'label']\n",
      "[ 1.44708148  0.7578142  -0.45226493  0.49498292 -1.01138155  0.9196928\n",
      " -0.30742702]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>glszm_SmallAreaEmphasis_logarithm2</th>\n",
       "      <th>glcm_InverseVariance_exponential2</th>\n",
       "      <th>glrlm_ShortRunLowGrayLevelEmphasis_square4</th>\n",
       "      <th>glszm_GrayLevelNonUniformity_wavelet-HHH2</th>\n",
       "      <th>glcm_Correlation_log-sigma-3-0-mm-3D2</th>\n",
       "      <th>glszm_ZoneEntropy_exponential4</th>\n",
       "      <th>firstorder_Skewness_logarithm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.447081</td>\n",
       "      <td>0.757814</td>\n",
       "      <td>-0.452265</td>\n",
       "      <td>0.494983</td>\n",
       "      <td>-1.011382</td>\n",
       "      <td>0.919693</td>\n",
       "      <td>-0.307427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.145508</td>\n",
       "      <td>-1.298190</td>\n",
       "      <td>-0.190610</td>\n",
       "      <td>-0.276422</td>\n",
       "      <td>-0.294524</td>\n",
       "      <td>0.616358</td>\n",
       "      <td>1.332940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0.691198</td>\n",
       "      <td>-0.340941</td>\n",
       "      <td>-0.438346</td>\n",
       "      <td>-0.121146</td>\n",
       "      <td>-0.288731</td>\n",
       "      <td>-1.451869</td>\n",
       "      <td>0.788919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0.542103</td>\n",
       "      <td>1.250093</td>\n",
       "      <td>-0.725200</td>\n",
       "      <td>0.342291</td>\n",
       "      <td>-0.524326</td>\n",
       "      <td>0.675756</td>\n",
       "      <td>0.528886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.124139</td>\n",
       "      <td>0.967292</td>\n",
       "      <td>-0.238149</td>\n",
       "      <td>-0.411194</td>\n",
       "      <td>-0.570905</td>\n",
       "      <td>0.180514</td>\n",
       "      <td>1.294495</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
       "0    1      0                            1.447081   \n",
       "1    2      1                           -0.145508   \n",
       "2    3      1                            0.691198   \n",
       "3    4      0                            0.542103   \n",
       "4    8      1                           -0.124139   \n",
       "\n",
       "   glcm_InverseVariance_exponential2  \\\n",
       "0                           0.757814   \n",
       "1                          -1.298190   \n",
       "2                          -0.340941   \n",
       "3                           1.250093   \n",
       "4                           0.967292   \n",
       "\n",
       "   glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
       "0                                   -0.452265   \n",
       "1                                   -0.190610   \n",
       "2                                   -0.438346   \n",
       "3                                   -0.725200   \n",
       "4                                   -0.238149   \n",
       "\n",
       "   glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
       "0                                   0.494983   \n",
       "1                                  -0.276422   \n",
       "2                                  -0.121146   \n",
       "3                                   0.342291   \n",
       "4                                  -0.411194   \n",
       "\n",
       "   glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
       "0                              -1.011382                        0.919693   \n",
       "1                              -0.294524                        0.616358   \n",
       "2                              -0.288731                       -1.451869   \n",
       "3                              -0.524326                        0.675756   \n",
       "4                              -0.570905                        0.180514   \n",
       "\n",
       "   firstorder_Skewness_logarithm2  \n",
       "0                       -0.307427  \n",
       "1                        1.332940  \n",
       "2                        0.788919  \n",
       "3                        0.528886  \n",
       "4                        1.294495  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSM_test3 = DSM_test_slist[1]\n",
    "DSM_test3.head()\n",
    "print(Dtag_cols)\n",
    "DSM_train3_y = DSM_train3['label'].to_list() \n",
    "DSM_train3_x = DSM_train3.drop(Dtag_cols, axis=1)\n",
    "DSM_train3_x = np.array(DSM_train3_x)\n",
    "print(DSM_train3_x[0])\n",
    "DSM_train3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8a2f26f9-89c6-45d7-ad51-0fdd4dd31097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       glszm_SmallAreaEmphasis_logarithm2  glcm_InverseVariance_exponential2  \\\n",
      "label                                                                          \n",
      "0                                      55                                 55   \n",
      "1                                      55                                 55   \n",
      "\n",
      "       glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
      "label                                               \n",
      "0                                              55   \n",
      "1                                              55   \n",
      "\n",
      "       glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
      "label                                              \n",
      "0                                             55   \n",
      "1                                             55   \n",
      "\n",
      "       glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
      "label                                                                          \n",
      "0                                         55                              55   \n",
      "1                                         55                              55   \n",
      "\n",
      "       firstorder_Skewness_logarithm2  \n",
      "label                                  \n",
      "0                                  55  \n",
      "1                                  55  \n"
     ]
    }
   ],
   "source": [
    "# 过采样\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "train_df = DSM_train_slist[1]\n",
    "train_df = train_df.sample(frac=1.0, random_state=123)\n",
    "train_df = train_df.drop(['pid'], axis=1)\n",
    "train_X, train_Y = train_df.loc[:, train_df.columns != 'label'], train_df.loc[:, train_df.columns == 'label']\n",
    "\n",
    "smote = SMOTE(k_neighbors=5, random_state=2022)\n",
    "X_smote, Y_smote = smote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "bsmote = BorderlineSMOTE(k_neighbors=2, random_state=2022)\n",
    "X_smote, Y_smote = bsmote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=3, random_state=42)\n",
    "X_smote, Y_smote = adasyn.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_smote, Y_smote = tl.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_smote, Y_smote = cc.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "print(df_smote.groupby('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "54d485bd-23b2-4a3d-aeac-62d41b3fe5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(DSM3_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "6b2a7fa1-c69d-41cf-b29f-f1122b845ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(DSM3_train_x))\n",
    "np.array(DSM3_train_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fcb5b23e-c3de-4835-b2d0-b5715b3a7aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['w1', 'w2', 'w3', 'w4', 'w5', 'w6', 'w7', 'w8', 'w9', 'w10', 'w11', 'w12', 'w13', 'w14', 'w15', 'w16', 'w17', 'w18', 'w19', 'w20', 'w21', 'w22', 'w23', 'w24', 'w25', 'w26', 'w27', 'w28', 'w29', 'w30', 'w31', 'w32', 'w33', 'w34', 'w35', 'w36', 'w37', 'w38', 'w39', 'w40', 'w41', 'w42', 'w43', 'w44', 'w45']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>glszm_SmallAreaEmphasis_logarithm2</th>\n",
       "      <th>glcm_InverseVariance_exponential2</th>\n",
       "      <th>glrlm_ShortRunLowGrayLevelEmphasis_square4</th>\n",
       "      <th>glszm_GrayLevelNonUniformity_wavelet-HHH2</th>\n",
       "      <th>glcm_Correlation_log-sigma-3-0-mm-3D2</th>\n",
       "      <th>glszm_ZoneEntropy_exponential4</th>\n",
       "      <th>firstorder_Skewness_logarithm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.082571</td>\n",
       "      <td>-1.467897</td>\n",
       "      <td>-0.371897</td>\n",
       "      <td>-0.403232</td>\n",
       "      <td>-0.163733</td>\n",
       "      <td>-0.537051</td>\n",
       "      <td>-0.044727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343019</td>\n",
       "      <td>1.377483</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>2.612101</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-1.606117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.248603</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>-0.536871</td>\n",
       "      <td>-2.005267</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-0.960588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>-0.316359</td>\n",
       "      <td>-1.180298</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.596528</td>\n",
       "      <td>-0.746848</td>\n",
       "      <td>1.090658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.067449</td>\n",
       "      <td>2.091546</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>-0.577231</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>1.330975</td>\n",
       "      <td>-2.159078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
       "0    1      1                           -0.082571   \n",
       "1    2      0                            0.343019   \n",
       "2    3      0                            1.248603   \n",
       "3    4      1                            0.044844   \n",
       "4    5      1                           -1.067449   \n",
       "\n",
       "   glcm_InverseVariance_exponential2  \\\n",
       "0                          -1.467897   \n",
       "1                           1.377483   \n",
       "2                           0.698196   \n",
       "3                          -0.316359   \n",
       "4                           2.091546   \n",
       "\n",
       "   glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
       "0                                   -0.371897   \n",
       "1                                   -0.326643   \n",
       "2                                   -0.326643   \n",
       "3                                   -1.180298   \n",
       "4                                    0.837405   \n",
       "\n",
       "   glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
       "0                                  -0.403232   \n",
       "1                                   2.612101   \n",
       "2                                  -0.536871   \n",
       "3                                   0.074876   \n",
       "4                                  -0.577231   \n",
       "\n",
       "   glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
       "0                              -0.163733                       -0.537051   \n",
       "1                               0.663478                        0.046500   \n",
       "2                              -2.005267                        0.046500   \n",
       "3                               0.596528                       -0.746848   \n",
       "4                               0.388151                        1.330975   \n",
       "\n",
       "   firstorder_Skewness_logarithm2  \n",
       "0                       -0.044727  \n",
       "1                       -1.606117  \n",
       "2                       -0.960588  \n",
       "3                        1.090658  \n",
       "4                       -2.159078  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# external test\n",
    "DSM_test_external = pd.read_csv(os.path.join(testdir, 'DSM_test_external.csv'))\n",
    "DSM3_extest_y = DSM_test_external['label']\n",
    "extest_pid = list(DSM_test_external['pid'].apply(lambda x: 'w'+str(x)))\n",
    "print(extest_pid)\n",
    "DSM3_extest_x = DSM_test_external.drop(Dtag_cols, axis=1)\n",
    "DSM3_extest_x = DSM3_extest_x\n",
    "DSM_test_external.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de55a4ce-c280-47f5-880b-99bd896c1212",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>glszm_SmallAreaEmphasis_logarithm2</th>\n",
       "      <th>glcm_InverseVariance_exponential2</th>\n",
       "      <th>glrlm_ShortRunLowGrayLevelEmphasis_square4</th>\n",
       "      <th>glszm_GrayLevelNonUniformity_wavelet-HHH2</th>\n",
       "      <th>glcm_Correlation_log-sigma-3-0-mm-3D2</th>\n",
       "      <th>glszm_ZoneEntropy_exponential4</th>\n",
       "      <th>firstorder_Skewness_logarithm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.082571</td>\n",
       "      <td>-1.467897</td>\n",
       "      <td>-0.371897</td>\n",
       "      <td>-0.403232</td>\n",
       "      <td>-0.163733</td>\n",
       "      <td>-0.537051</td>\n",
       "      <td>-0.044727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343019</td>\n",
       "      <td>1.377483</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>2.612101</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-1.606117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.248603</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>-0.536871</td>\n",
       "      <td>-2.005267</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-0.960588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>-0.316359</td>\n",
       "      <td>-1.180298</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.596528</td>\n",
       "      <td>-0.746848</td>\n",
       "      <td>1.090658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.067449</td>\n",
       "      <td>2.091546</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>-0.577231</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>1.330975</td>\n",
       "      <td>-2.159078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
       "0    1      1                           -0.082571   \n",
       "1    2      0                            0.343019   \n",
       "2    3      0                            1.248603   \n",
       "3    4      1                            0.044844   \n",
       "4    5      1                           -1.067449   \n",
       "\n",
       "   glcm_InverseVariance_exponential2  \\\n",
       "0                          -1.467897   \n",
       "1                           1.377483   \n",
       "2                           0.698196   \n",
       "3                          -0.316359   \n",
       "4                           2.091546   \n",
       "\n",
       "   glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
       "0                                   -0.371897   \n",
       "1                                   -0.326643   \n",
       "2                                   -0.326643   \n",
       "3                                   -1.180298   \n",
       "4                                    0.837405   \n",
       "\n",
       "   glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
       "0                                  -0.403232   \n",
       "1                                   2.612101   \n",
       "2                                  -0.536871   \n",
       "3                                   0.074876   \n",
       "4                                  -0.577231   \n",
       "\n",
       "   glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
       "0                              -0.163733                       -0.537051   \n",
       "1                               0.663478                        0.046500   \n",
       "2                              -2.005267                        0.046500   \n",
       "3                               0.596528                       -0.746848   \n",
       "4                               0.388151                        1.330975   \n",
       "\n",
       "   firstorder_Skewness_logarithm2  \n",
       "0                       -0.044727  \n",
       "1                       -1.606117  \n",
       "2                       -0.960588  \n",
       "3                        1.090658  \n",
       "4                       -2.159078  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DSM_extest3 = DSM_test_external.copy()\n",
    "print(len(DSM_extest3))\n",
    "DSM_extest3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "8dad4683-72c3-4beb-b07b-de895d734557",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20188/1605965934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                    )\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSM3_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDSM3_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbest_hp_now\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=5,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='balanced_accuracy'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(DSM3_train_x, DSM3_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cda5d-4b74-44eb-b6a1-48dda09e47ed",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078d73a8-0246-4cbd-a60f-83c657ab9758",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[150,200,250],\n",
    "                          'max_features':[2,3,4],\n",
    "                          'max_depth':[10, 20, 30],\n",
    "                          'min_samples_split':[8,10,12], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8,16]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=3,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               #scoring='balanced_accuracy'\n",
    "                                               scoring='neg_log_loss'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(DSM3_train_x, DSM3_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "230589cb-b653-4f35-9f27-50b90754f832",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(DSM3_train_x))\n",
    "t1 = np.array(DSM3_extest_x)\n",
    "print(len(DSM3_extest_x))\n",
    "all_train_x = np.concatenate((DSM3_train_x, t1),axis=0)\n",
    "# print(len(all_train_x))\n",
    "\n",
    "#print(DSM3_extest_x)\n",
    "print(DSM3_train_x.shape)\n",
    "print(t1.shape)\n",
    "print(all_train_x.shape)\n",
    "\n",
    "print(DSM3_train_y)\n",
    "print(list(DSM3_extest_y))\n",
    "all_train_y = DSM3_train_y + list(DSM3_extest_y)\n",
    "print(len(all_train_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ff2997-6d32-477a-9733-a8e0668ea88c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[160,240,300],\n",
    "                          'max_features':[2,3,4,5],\n",
    "                          'max_depth':[20,22],\n",
    "                          'min_samples_split':[7,8,10], # Greater than 1\n",
    "                          'min_samples_leaf':[16,32]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=10,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='recall_macro')\n",
    "                                               #scoring='neg_log_loss')\n",
    "random_forest_model_test_3_random.fit(all_train_x, all_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71610ea4-0a1f-42ff-9412-ff15b582b3c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "sorted(sklearn.metrics.SCORERS.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f396b3-7787-498c-aac1-6d03f86df130",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5885566f-9461-4348-9ef5-f6e3975aed75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "DSM3=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = DSM3.score(DSM3_test_x, DSM3_test_y)\n",
    "print(score)\n",
    "joblib.dump(DSM3, os.path.join(modeldir, DSM3_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c8828-742e-43f0-8b47-58f1bcfeb0e1",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "380ff187-9fcd-4830-9b7a-a4ece69529a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    pid  dataset  y_true  y_pred  y_score0  y_score1\n",
      "0   i91  traning       0       0  0.595680  0.404320\n",
      "1   i76  traning       1       1  0.336130  0.663870\n",
      "2    i4  traning       1       1  0.448695  0.551305\n",
      "3  i124  traning       0       0  0.662772  0.337228\n",
      "4   i20  traning       1       0  0.513240  0.486760\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8164556962025317,\n",
       " 'recall': 0.8349514563106796,\n",
       " 'precision': 0.8775510204081632,\n",
       " 'f1': 0.8557213930348259,\n",
       " 'auc': 0.8875551632833187,\n",
       " 'specificity': 0.7818181818181819}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= joblib.load(os.path.join(modeldir, DSM3_model)) \n",
    "model= joblib.load(os.path.join('./Model_old/', DSM3_model)) \n",
    "predict_label = model.predict(DSM_train3_x) #预测的标签\n",
    "predict_score = model.predict_proba(DSM_train3_x) #得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = DSM_train3_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':train_pid, 'dataset':'traning', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "print(tmp_df.head())\n",
    "# tmp_df['dataset'] = 'training'\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "72d01be7-6011-414e-b3fd-baf8e1606fa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "nomogram_train = DSM_train3.copy()\n",
    "nomogram_train['radiomics_score'] = predict_score[:,1]\n",
    "nomogram_train.head(2)\n",
    "nomogram_train['dataset']='training'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4d503867-2025-43b5-b5da-7c8a0521bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6857142857142857,\n",
       " 'recall': 0.782608695652174,\n",
       " 'precision': 0.75,\n",
       " 'f1': 0.7659574468085107,\n",
       " 'auc': 0.720108695652174,\n",
       " 'specificity': 0.5}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, DSM3_model)) \n",
    "model_forest= joblib.load(os.path.join('./Model_old/', DSM3_model)) \n",
    "predict_label = model_forest.predict(DSM3_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(DSM3_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = DSM3_test_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':test_pid, 'dataset':'test', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "test_df = tmp_df.copy()\n",
    "tmp_df.to_csv('../20230108/test_radio.csv',index=0)\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "95879c24-af00-4561-bc87-35a7a741ae30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.79708496  0.5927037  -0.55790057 -0.66888717 -0.92396195 -0.0422019\n",
      "  0.36268925]\n",
      "   pid  label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
      "0    5      1                            0.797085   \n",
      "1    6      1                            0.710836   \n",
      "\n",
      "   glcm_InverseVariance_exponential2  \\\n",
      "0                           0.592704   \n",
      "1                           0.190043   \n",
      "\n",
      "   glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
      "0                                   -0.557901   \n",
      "1                                   -0.354496   \n",
      "\n",
      "   glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
      "0                                  -0.668887   \n",
      "1                                   0.938193   \n",
      "\n",
      "   glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
      "0                              -0.923962                       -0.042202   \n",
      "1                              -0.438992                        0.703784   \n",
      "\n",
      "   firstorder_Skewness_logarithm2  \n",
      "0                        0.362689  \n",
      "1                        0.044257  \n"
     ]
    }
   ],
   "source": [
    "print(DSM3_test_x[0])\n",
    "print(DSM_test3.head(2))\n",
    "nomogram_test = DSM_test3.copy()\n",
    "nomogram_test['radiomics_score'] = predict_score[:,1]\n",
    "nomogram_test.head(2)\n",
    "nomogram_test['dataset']='test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "695f4c46-a980-47dc-9fc7-73edc92e2dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'DSM3_extest_x' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4891/3796230590.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mjoblib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodeldir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDSM3_model\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# model= joblib.load(os.path.join('./Model_old/', DSM3_model))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mpredict_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSM3_extest_x\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#预测的标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mpredict_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSM3_extest_x\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDSM3_extest_y\u001b[0m  \u001b[0;31m#真实标签\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DSM3_extest_x' is not defined"
     ]
    }
   ],
   "source": [
    "model= joblib.load(os.path.join(modeldir, DSM3_model)) \n",
    "# model= joblib.load(os.path.join('./Model_old/', DSM3_model)) \n",
    "predict_label = model.predict(DSM3_extest_x) #预测的标签\n",
    "predict_score = model.predict_proba(DSM3_extest_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = DSM3_extest_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':extest_pid, 'dataset':'external', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "tmp_df.to_csv('../20230108/extest_radio.csv',index=0)\n",
    "extest_df = tmp_df.copy()\n",
    "label = DSM3_extest_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d80b68d5-d9f1-41e6-a22e-a5ad60cecf48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "45\n",
      "45\n",
      "45\n"
     ]
    }
   ],
   "source": [
    "print(len(DSM3_extest_x))\n",
    "nomogram_extest = DSM_extest3.copy()\n",
    "print(len(nomogram_extest))\n",
    "print(len(DSM3_extest_x))\n",
    "nomogram_extest['radiomics_score'] = predict_score[:,1]\n",
    "nomogram_extest.head(2)\n",
    "nomogram_extest['dataset']='external'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad996a9f-fd14-4e32-adaa-873fe8f1be11",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat([train_df, test_df, extest_df], axis=0)\n",
    "all_df.to_csv('../20230108/all_radio.csv', index=0)\n",
    "nomogram_all = pd.concat([nomogram_train, nomogram_test, nomogram_extest])\n",
    "nomogram_all.to_csv('./out_data/nomogram_feas_radiomics.csv',index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03d314-82f9-46c6-993d-7ba3b9e4870b",
   "metadata": {},
   "source": [
    "### ASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d3d182e7-7df2-45b4-b46f-6714c73f87dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Feature_filter/Feas_data_test\n"
     ]
    }
   ],
   "source": [
    "# Load the ASM features.\n",
    "Atag_cols = ['pid', 'label']\n",
    "ASM_train = pd.read_csv(os.path.join(traindir, 'ASM_mrmr_feas.csv')) \n",
    "ASM_test = pd.read_csv(os.path.join(testdir, 'ASM_test.csv')) \n",
    "print(testdir)\n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "# ASM_train = ASM_train.sample(frac=1.0, random_state=random_state) \n",
    "train_pid = ASM_train['pid']\n",
    "ASM_train_y = ASM_train['label'] \n",
    "\n",
    "ASM_train_x = ASM_train.drop(Atag_cols, axis=1) \n",
    "ASM_train_x = standardscaler.fit_transform(ASM_train_x) \n",
    "# Test data\n",
    "# ASM_test = ASM_test.sample(frac=1.0, random_state=random_state)\n",
    "ASM_test_y = ASM_test['label']\n",
    "test_pid = ASM_test['pid']\n",
    "ASM_test_x =ASM_test.drop(Atag_cols, axis=1)\n",
    "ASM_test_x = standardscaler.fit_transform(ASM_test_x)\n",
    "\n",
    "ASM_model = f'RandomForest_ASM.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61647f6c-ca2f-4918-8257-b3d2a4764a87",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c8206-278f-4770-9b58-d3101a9022ef",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a544583-99e6-4009-846c-8bb284eec697",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[100, 150, 200],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[200, 220, 300],\n",
    "                          'min_samples_split':[4,5,6], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8],\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc')\n",
    "random_forest_model_test_2_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b01d55-d717-47d6-b75d-f46d9ac28398",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[200, 300],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[200],\n",
    "                          'min_samples_split':[5], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='accuracy')\n",
    "random_forest_model_test_3_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8f59e-cc7d-4ae1-9611-fd154c29842b",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55aa9f9-3c82-48f4-9aa5-2174e3c0b2cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "ASM=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = ASM.score(ASM_test_x, ASM_test_y)\n",
    "print(score)\n",
    "joblib.dump(ASM, os.path.join(modeldir, ASM_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9dc6f-a068-46ca-a5dd-0c6ca78a6fe0",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "28b0403b-fc42-491b-85fc-05d325a4c75f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid  dataset  y_true  y_pred  y_score0  y_score1\n",
      "0   25  traning       1       1  0.150769  0.849231\n",
      "1  230  traning       1       1  0.381310  0.618690\n",
      "2  171  traning       1       1  0.101922  0.898078\n",
      "3   61  traning       1       1  0.110356  0.889644\n",
      "4   40  traning       1       1  0.294703  0.705297\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.8227848101265823,\n",
       " 'recall': 0.9514563106796117,\n",
       " 'precision': 0.8099173553719008,\n",
       " 'f1': 0.8749999999999999,\n",
       " 'auc': 0.9330979699911739,\n",
       " 'specificity': 0.5818181818181818}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, ASM_model)) \n",
    "predict_label = model_forest.predict(ASM_train_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(ASM_train_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = ASM_train_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':train_pid, 'dataset':'traning', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "print(tmp_df.head())\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "39198ee9-61c6-4023-9459-97dae3dc5325",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   pid  dataset  y_true  y_pred  y_score0  y_score1\n",
      "0  224  traning       1       1  0.404221  0.595779\n",
      "1   30  traning       1       0  0.658133  0.341867\n",
      "2  157  traning       0       1  0.399216  0.600784\n",
      "3  117  traning       1       1  0.336892  0.663108\n",
      "4   24  traning       1       1  0.298579  0.701421\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7571428571428571,\n",
       " 'recall': 0.9565217391304348,\n",
       " 'precision': 0.7457627118644068,\n",
       " 'f1': 0.8380952380952381,\n",
       " 'auc': 0.6838768115942029,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, ASM_model)) \n",
    "predict_label = model_forest.predict(ASM_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(ASM_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = ASM_test_y  #真实标签\n",
    "tmp_df =  pd.DataFrame({'pid':test_pid, 'dataset':'traning', 'y_true':label, 'y_pred': predict_label, 'y_score0': predict_score[:,0], 'y_score1':predict_score[:,1]})\n",
    "print(tmp_df.head())\n",
    "train_df = tmp_df.copy()\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "26e5b077-ceac-4e82-97d8-d5af854a5740",
   "metadata": {},
   "outputs": [],
   "source": [
    "asm_df = pd.concat([train_df, test_df])\n",
    "asm_df.to_csv('./radiomics_result_20230406/asm.csv', index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2feac5-11c2-4023-b0ba-b8285bd86e1e",
   "metadata": {},
   "source": [
    "### Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40f9bcfb-41e8-424e-81be-881e9b01b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Clinical features.\n",
    "Atag_cols = ['pid', 'label']\n",
    "Clinical_train = pd.read_csv(os.path.join(traindir, 'clinical_lasso_sel.csv')) \n",
    "Clinical_test = pd.read_csv(os.path.join(testdir, 'clinical_test.csv')) \n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "Clinical_train = Clinical_train.sample(frac=1.0, random_state=random_state) \n",
    "Clinical_train_y = Clinical_train['label'] \n",
    "Clinical_train_x = Clinical_train.drop(Atag_cols, axis=1) \n",
    "#Clinical_train_x = standardscaler.fit_transform(Clinical_train_x) \n",
    "# Test data\n",
    "#Clinical_test = Clinical_test.sample(frac=1.0, random_state=random_state)\n",
    "Clinical_test_y = np.array(Clinical_test['label'])\n",
    "Clinical_test_x = np.array(Clinical_test.drop(Dtag_cols, axis=1))\n",
    "#Clinical_test_x = standardscaler.fit_transform(Clinical_test_x)\n",
    "\n",
    "Clinical_model = f'RandomForest_Clinical.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed8741fe-8749-4ea7-8840-0eafa1f2cc6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 过采样\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "Clinical_train = Clinical_train.sample(frac=1.0, random_state=123)\n",
    "Clinical_train = Clinical_train.drop(['pid'], axis=1)\n",
    "train_X, train_Y = Clinical_train.loc[:, Clinical_train.columns != 'label'], Clinical_train.loc[:, Clinical_train.columns == 'label']\n",
    "\n",
    "smote = SMOTE(k_neighbors=3, random_state=2022)\n",
    "X_smote, Y_smote = smote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "bsmote = BorderlineSMOTE(k_neighbors=4, random_state=2022)\n",
    "X_smote, Y_smote = bsmote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=3, random_state=42)\n",
    "X_smote, Y_smote = adasyn.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_smote, Y_smote = tl.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_smote, Y_smote = cc.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "print(df_smote.groupby('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e858ce-9ecd-44be-97d3-f0c263d1ad43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996575d-fed8-46ea-b547-685ddddb2b85",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee04782-1eb3-484e-9ddf-47ebbd00953d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[40, 50, 60],\n",
    "                          'max_features':[3,4,5],\n",
    "                          'max_depth':[30, 40, 50],\n",
    "                          'min_samples_split':[2,3,4], # Greater than 1\n",
    "                          'min_samples_leaf':[1, 2, 3],\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='balanced_accuracy')\n",
    "random_forest_model_test_2_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e11147f-0885-46be-b70a-e32fb0189b0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[30,40],\n",
    "                          'max_features':[5,6],\n",
    "                          'max_depth':[20,30],\n",
    "                          'min_samples_split':[3,4,5], # Greater than 1\n",
    "                          'min_samples_leaf':[2,4,8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='balanced_accuracy')\n",
    "random_forest_model_test_3_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df164134-9ca4-4d9b-8db7-50835bf7bc8e",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f56be-3db5-4054-892f-53f31438c56c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "Clinical=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = Clinical.score(Clinical_test_x, Clinical_test_y)\n",
    "print(score)\n",
    "joblib.dump(Clinical, os.path.join(modeldir, Clinical_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac175e8-818e-4520-b9a2-4e8371d39c27",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc6b6e73-41db-4357-ac1b-196a0cdfe89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, Clinical_model)) \n",
    "predict_label = model_forest.predict(Clinical_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(Clinical_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = Clinical_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47ec756-c41d-4b6b-8fcf-57fd9778b35f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chongfu1",
   "language": "python",
   "name": "chongfu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

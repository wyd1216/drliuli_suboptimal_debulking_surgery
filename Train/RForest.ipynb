{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a0838ac-54b8-4f84-85f0-c0a44a3f351c",
   "metadata": {},
   "source": [
    "## Train the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a37e350-9f25-43ee-a37c-86e2194a7c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import joblib\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pprint import pprint\n",
    "from sklearn import metrics\n",
    "from openpyxl import load_workbook\n",
    "from sklearn.tree import export_graphviz\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db50f8e-06ff-4fb0-a584-bbd8c103f704",
   "metadata": {},
   "source": [
    "## (1) Random Forest\n",
    "\n",
    "+ 重要参数:\n",
    "  1. n_estimators: \n",
    "  2. max_depth\n",
    "  3. max_features\n",
    "  4. min_samples_split\n",
    "  5. min_samples_leaf\n",
    "  6. bootstrap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c8a82886-6c49-4703-be86-45be8eb831b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix    #导入计算混淆矩阵的包\n",
    "def specificity_score(y_true, y_pred):\n",
    "    C = confusion_matrix(y_true, y_pred)\n",
    "    TP = C[1,1]\n",
    "    FP = C[0,1]\n",
    "    TN = C[0,0]\n",
    "    FN = C[1,0]\n",
    "    specificity = TN/(TN+FP)\n",
    "    return specificity\n",
    "\n",
    "def classification_evaluation(y_true, y_pred, y_score):\n",
    "    precision = metrics.precision_score(y_true, y_pred)\n",
    "    recall = metrics.recall_score(y_true, y_pred)\n",
    "    accuracy = metrics.accuracy_score(y_true, y_pred)\n",
    "    auc = metrics.roc_auc_score(y_true, y_score)\n",
    "    f1 = metrics.f1_score(y_true, y_pred)\n",
    "    specificity = specificity_score(y_true, y_pred)\n",
    "    evaluation = {'accuracy':accuracy, 'recall':recall, 'precision':precision, 'f1':f1, 'auc':auc, 'specificity':specificity}\n",
    "    return evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f15fab-af4b-4c96-a1d8-8dde733f967c",
   "metadata": {},
   "source": [
    "### Global params setting and load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c8e83700-f1c0-4340-ac8c-cf7cfaa1f3d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "traindir = '../Feature_filter/Feas_data'\n",
    "testdir = '../Feature_filter/Feas_data_test'\n",
    "imgdir = os.path.join(cwd, 'IMG')\n",
    "modeldir = os.path.join(cwd, 'Model')\n",
    "tag_cols = ['pid', 'label', 'series', 'image', 'mask']\n",
    "sequence_id = [2, 3, 4]\n",
    "# Generate the random seed\n",
    "random_state = random.randint(1,10000)\n",
    "\n",
    "# Load the SSM features.\n",
    "SSM_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]\n",
    "SSM_test_slist = [pd.read_excel(os.path.join(testdir, 'SSM_test.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0a1cb9e-a623-4388-87ee-4a2d18c2abd7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pid', 'label', 'series', 'image', 'mask', 'glszm_SmallAreaEmphasis_logarithm', 'glcm_InverseVariance_exponential', 'glszm_GrayLevelNonUniformity_wavelet-HHH', 'firstorder_Skewness_logarithm', 'glcm_Correlation_log-sigma-3-0-mm-3D']\n",
      "['pid', 'label', 'series', 'image', 'mask', 'gldm_DependenceVariance_wavelet-LLH', 'ngtdm_Contrast_wavelet-HHL', 'firstorder_Skewness_log-sigma-2-0-mm-3D', 'glcm_Imc2_wavelet-HHH', 'glrlm_RunEntropy_exponential']\n",
      "['pid', 'label', 'series', 'image', 'mask', 'glrlm_ShortRunLowGrayLevelEmphasis_square', 'glszm_ZoneEntropy_exponential']\n",
      "6 6 3\n"
     ]
    }
   ],
   "source": [
    "# Print features\n",
    "SSM_features_list = [df.columns for df in SSM_train_slist]\n",
    "print(SSM_features_list[0].to_list())\n",
    "print(SSM_features_list[1].to_list())\n",
    "print(SSM_features_list[2].to_list())\n",
    "print(len(SSM_features_list[0])-4, len(SSM_features_list[1])-4, len(SSM_features_list[2])-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3768fc6b-986f-429f-b938-e1a25ff91e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "SSM_train_slist = [df.sample(frac=1.0, random_state=random_state) for df in SSM_train_slist]\n",
    "SSM_train_y = [df['label'] for df in SSM_train_slist]\n",
    "SSM_train_x = [df.drop(tag_cols, axis=1) for df in SSM_train_slist]\n",
    "SSM_train_x = [standardscaler.fit_transform(df) for df in SSM_train_x]\n",
    "# Test data\n",
    "SSM_test_slist = [df.sample(frac=1.0, random_state=random_state) for df in SSM_test_slist]\n",
    "SSM_test_y = [df['label'] for df in SSM_test_slist]\n",
    "SSM_test_x = [df.drop(tag_cols, axis=1) for df in SSM_test_slist]\n",
    "SSM_test_x = [standardscaler.fit_transform(df) for df in SSM_test_x]\n",
    "\n",
    "SSM2_train_y, SSM3_train_y, SSM4_train_y = (y_.to_list() for y_ in SSM_train_y)             \n",
    "SSM2_train_x, SSM3_train_x, SSM4_train_x = (x_ for x_ in SSM_train_x)\n",
    "SSM2_test_y, SSM3_test_y, SSM4_test_y = (y_.to_list() for y_ in SSM_test_y)\n",
    "SSM2_test_x, SSM3_test_x, SSM4_test_x = (x_ for x_ in SSM_test_x)\n",
    "SSM2_model, SSM3_model, SSM4_model = (f'RandomForest_SSM{i+2}.model' for i in range(3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eedf637-cdd3-48a6-b19c-cac679fff0d1",
   "metadata": {},
   "source": [
    "### 随机森林系统调参"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beab93fb-6af0-4857-84ce-91772a6391a1",
   "metadata": {},
   "source": [
    "### SSM2\n",
    "#### Get data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49942c7-2803-45e8-9a80-c69d5b03424d",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优\n",
    "+ 按照排列组合来计算的话，会有很多很多种组合方式，如果要一一尝试未免也太麻烦了。因此，我们用到RandomizedSearchCV这一功能——其将随机匹配每一种超参数组合，并输出最优的组合。换句话说，我们用RandomizedSearchCV来进行随机的排列，而不是对所有的超参数排列组合方法进行遍历。这样子确实可以节省很多时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade62c72-b763-412e-ba05-0688ddfa28df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 300 candidates, totalling 900 fits\n",
      "{'max_depth': 490,\n",
      " 'max_features': 'sqrt',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 1100}\n"
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=3,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a433a93b-aede-48ba-8a1d-b3e5d928631f",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3023fcb7-7373-47d2-8893-b6e38daba533",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 243 candidates, totalling 972 fits\n",
      "{'max_depth': 300,\n",
      " 'max_features': 2,\n",
      " 'min_samples_leaf': 10,\n",
      " 'min_samples_split': 3,\n",
      " 'n_estimators': 900}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[900, 1100, 1200],\n",
    "                          'max_features':[2, 3, 4],\n",
    "                          'max_depth':[300, 490, 600],\n",
    "                          'min_samples_split':[2, 3, 4], # Greater than 1\n",
    "                          'min_samples_leaf':[6, 8, 10]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "277b20bd-2a7c-4368-8040-21280fd8df95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 6 folds for each of 8 candidates, totalling 48 fits\n",
      "{'max_depth': 500,\n",
      " 'max_features': 2,\n",
      " 'min_samples_leaf': 12,\n",
      " 'min_samples_split': 3,\n",
      " 'n_estimators': 700}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[700,800],\n",
    "                          'max_features':[2],\n",
    "                          'max_depth':[400,500],\n",
    "                          'min_samples_split':[3], # Greater than 1\n",
    "                          'min_samples_leaf':[12, 13]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=6,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                              scoring='accuracy'\n",
    "                                              )\n",
    "random_forest_model_test_3_random.fit(SSM2_train_x, SSM2_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "238e8fae-f66a-40f3-aeb4-ab6616a87b12",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c1b276be-30f1-4669-99fb-8e13c5f92073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7571428571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_SSM2.model']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM2=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM2.predict(SSM2_test_x)\n",
    "score = SSM2.score(SSM2_test_x, SSM2_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM2, os.path.join(modeldir, SSM2_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fc0005-8108-4cb9-92c2-4276d0370c16",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "441f2f38-29ee-42a7-bec8-3ac059975e4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7571428571428571,\n",
       " 'recall': 0.9782608695652174,\n",
       " 'precision': 0.7377049180327869,\n",
       " 'f1': 0.8411214953271028,\n",
       " 'auc': 0.6548913043478262,\n",
       " 'specificity': 0.3333333333333333}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM2_model)) \n",
    "predict_label = model_forest.predict(SSM2_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM2_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM2_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97235b70-eeea-44fc-ab32-6f6436112f83",
   "metadata": {},
   "source": [
    "### SSM3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "746bf5e8-fee0-419b-8232-e02fcd83a636",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d30a2ccc-4211-4e7d-bc49-4161761192fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 300 candidates, totalling 1200 fits\n",
      "{'max_depth': 120,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 450}\n"
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61c4b912-82c3-4e24-a141-8bf3d62d724c",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1c355302-ead1-4afd-a26e-0c54d48dadcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n",
      "{'max_depth': 120,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 400}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[400,450,500],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[100, 120, 200],\n",
    "                          'min_samples_split':[4,5,8], # Greater than 1\n",
    "                          'min_samples_leaf':[1,2]\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1)\n",
    "random_forest_model_test_2_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3f6aede5-8f98-4e91-8d3b-0f62b9751e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 4 candidates, totalling 20 fits\n",
      "{'max_depth': 210,\n",
      " 'max_features': 5,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 2,\n",
      " 'n_estimators': 1600}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[1600],\n",
    "                          'max_features':[4,5],\n",
    "                          'max_depth':[200, 210],\n",
    "                          'min_samples_split':[2], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_3_random.fit(SSM3_train_x, SSM3_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd346ab1-6c8e-47fe-ab8c-4d4613692292",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dbf0cc4b-f519-4cfe-9ae1-a6194d29beb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_SSM3.model']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM3=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM3.predict(SSM3_test_x)\n",
    "score = SSM3.score(SSM3_test_x, SSM3_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM3, os.path.join(modeldir, SSM3_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84058010-afca-4dc1-b760-2ba723495f3a",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1504aed5-3a5e-43b8-9eb5-b00ecc497107",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7,\n",
       " 'recall': 0.8695652173913043,\n",
       " 'precision': 0.7272727272727273,\n",
       " 'f1': 0.792079207920792,\n",
       " 'auc': 0.6639492753623188,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = SSM3\n",
    "predict_label = model_forest.predict(SSM3_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM3_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM3_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4055b8-456e-4499-9084-d9c83b28c8fc",
   "metadata": {},
   "source": [
    "### SSM4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e740d8e-4e6f-4ad3-adb3-785fb5427b2a",
   "metadata": {},
   "source": [
    "#### 超参数随机匹配择优\n",
    "+ 按照排列组合来计算的话，会有很多很多种组合方式，如果要一一尝试未免也太麻烦了。因此，我们用到RandomizedSearchCV这一功能——其将随机匹配每一种超参数组合，并输出最优的组合。换句话说，我们用RandomizedSearchCV来进行随机的排列，而不是对所有的超参数排列组合方法进行遍历。这样子确实可以节省很多时间。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66b9f522-8669-49a9-b79b-20c382887b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 300 candidates, totalling 1200 fits\n",
      "{'max_depth': 400,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 10,\n",
      " 'n_estimators': 2750}\n"
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66807b0d-3564-4ea9-9adf-4b3e5ec750f8",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e0c22f27-22c7-4915-b949-837fa210f02c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 54 candidates, totalling 270 fits\n",
      "{'max_depth': 400,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 8,\n",
      " 'n_estimators': 2500}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[2500, 2750],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[300,400,500],\n",
    "                          'min_samples_split':[8,10,12], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8,12]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a8fdee37-d6fa-4991-a06b-095851f1147d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "{'max_depth': 400,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 8,\n",
      " 'n_estimators': 2500}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[2500],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[400],\n",
    "                          'min_samples_split':[8], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='accuracy')\n",
    "random_forest_model_test_3_random.fit(SSM4_train_x, SSM4_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6b09cb-702c-465d-8a52-2a8a0b2ea2ee",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "43ac1212-e511-44f7-88bb-4f1faabbee71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428571428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_SSM4.model']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "SSM4=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "random_forest_predict=SSM4.predict(SSM4_test_x)\n",
    "score = SSM4.score(SSM4_test_x, SSM4_test_y)\n",
    "print(score)\n",
    "joblib.dump(SSM4, os.path.join(modeldir, SSM4_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c01208cc-7ebd-4744-aed2-53b4705fa8bd",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d256bab7-c8e5-43e5-86b8-d3bcdbba3e98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7428571428571429,\n",
       " 'recall': 0.9347826086956522,\n",
       " 'precision': 0.7413793103448276,\n",
       " 'f1': 0.826923076923077,\n",
       " 'auc': 0.7001811594202899,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, SSM4_model)) \n",
    "predict_label = model_forest.predict(SSM4_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(SSM4_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = SSM4_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90d60db2-1d01-4d30-9385-5e71dfbcf695",
   "metadata": {},
   "source": [
    "### DSM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "b416aeae-c2e4-4b2b-99a8-0a6b6606d9d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the DSM features.\n",
    "Dtag_cols = ['pid', 'label']\n",
    "DSM_train_slist = [pd.read_excel(os.path.join(traindir, 'DSM_feas_mrmr_sel.xlsx'), sheet_name=f'no_sequence{num}') for num in sequence_id]\n",
    "DSM_test_slist = [pd.read_excel(os.path.join(testdir, 'DSM_test.xlsx'), sheet_name=f'no_sequence{num}') for num in sequence_id]\n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "DSM_train_slist = [df.sample(frac=1.0, random_state=random_state) for df in DSM_train_slist]\n",
    "DSM_train_y = [df['label'] for df in DSM_train_slist]\n",
    "DSM_train_x = [df.drop(Dtag_cols, axis=1) for df in DSM_train_slist]\n",
    "#DSM_train_x = [standardscaler.fit_transform(df) for df in DSM_train_x]\n",
    "# Test data\n",
    "#DSM_test_slist = [df.sample(frac=1.0, random_state=random_state) for df in DSM_test_slist]\n",
    "DSM_test_y = [df['label'] for df in DSM_test_slist]\n",
    "DSM_test_x = [df.drop(Dtag_cols, axis=1) for df in DSM_test_slist]\n",
    "#DSM_test_x = [standardscaler.fit_transform(df) for df in DSM_test_x]\n",
    "\n",
    "DSM2_train_y, DSM3_train_y, DSM4_train_y = (y_.to_list() for y_ in DSM_train_y)             \n",
    "DSM2_train_x, DSM3_train_x, DSM4_train_x = (np.array(x_) for x_ in DSM_train_x)\n",
    "DSM2_test_y, DSM3_test_y, DSM4_test_y = (y_.to_list() for y_ in DSM_test_y)\n",
    "DSM2_test_x, DSM3_test_x, DSM4_test_x = (np.array(x_) for x_ in DSM_test_x)\n",
    "DSM2_model, DSM3_model, DSM4_model = (f'RandomForest_DSM{i+2}.model' for i in range(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "8a2f26f9-89c6-45d7-ad51-0fdd4dd31097",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       glszm_SmallAreaEmphasis_logarithm2  glcm_InverseVariance_exponential2  \\\n",
      "label                                                                          \n",
      "0                                      55                                 55   \n",
      "1                                      55                                 55   \n",
      "\n",
      "       glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
      "label                                               \n",
      "0                                              55   \n",
      "1                                              55   \n",
      "\n",
      "       glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
      "label                                              \n",
      "0                                             55   \n",
      "1                                             55   \n",
      "\n",
      "       glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
      "label                                                                          \n",
      "0                                         55                              55   \n",
      "1                                         55                              55   \n",
      "\n",
      "       firstorder_Skewness_logarithm2  \n",
      "label                                  \n",
      "0                                  55  \n",
      "1                                  55  \n"
     ]
    }
   ],
   "source": [
    "# 过采样\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "train_df = DSM_train_slist[1]\n",
    "train_df = train_df.sample(frac=1.0, random_state=123)\n",
    "train_df = train_df.drop(['pid'], axis=1)\n",
    "train_X, train_Y = train_df.loc[:, train_df.columns != 'label'], train_df.loc[:, train_df.columns == 'label']\n",
    "\n",
    "smote = SMOTE(k_neighbors=5, random_state=2022)\n",
    "X_smote, Y_smote = smote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "bsmote = BorderlineSMOTE(k_neighbors=2, random_state=2022)\n",
    "X_smote, Y_smote = bsmote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=3, random_state=42)\n",
    "X_smote, Y_smote = adasyn.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_smote, Y_smote = tl.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_smote, Y_smote = cc.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "\n",
    "DSM3_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "DSM3_train_y = np.array(df_smote['label'].to_list())\n",
    "print(df_smote.groupby('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "54d485bd-23b2-4a3d-aeac-62d41b3fe5cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(DSM3_train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "6b2a7fa1-c69d-41cf-b29f-f1122b845ac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "55"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(DSM3_train_x))\n",
    "np.array(DSM3_train_y).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "fcb5b23e-c3de-4835-b2d0-b5715b3a7aba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>glszm_SmallAreaEmphasis_logarithm2</th>\n",
       "      <th>glcm_InverseVariance_exponential2</th>\n",
       "      <th>glrlm_ShortRunLowGrayLevelEmphasis_square4</th>\n",
       "      <th>glszm_GrayLevelNonUniformity_wavelet-HHH2</th>\n",
       "      <th>glcm_Correlation_log-sigma-3-0-mm-3D2</th>\n",
       "      <th>glszm_ZoneEntropy_exponential4</th>\n",
       "      <th>firstorder_Skewness_logarithm2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.082571</td>\n",
       "      <td>-1.467897</td>\n",
       "      <td>-0.371897</td>\n",
       "      <td>-0.403232</td>\n",
       "      <td>-0.163733</td>\n",
       "      <td>-0.537051</td>\n",
       "      <td>-0.044727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.343019</td>\n",
       "      <td>1.377483</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>2.612101</td>\n",
       "      <td>0.663478</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-1.606117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1.248603</td>\n",
       "      <td>0.698196</td>\n",
       "      <td>-0.326643</td>\n",
       "      <td>-0.536871</td>\n",
       "      <td>-2.005267</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>-0.960588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0.044844</td>\n",
       "      <td>-0.316359</td>\n",
       "      <td>-1.180298</td>\n",
       "      <td>0.074876</td>\n",
       "      <td>0.596528</td>\n",
       "      <td>-0.746848</td>\n",
       "      <td>1.090658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.067449</td>\n",
       "      <td>2.091546</td>\n",
       "      <td>0.837405</td>\n",
       "      <td>-0.577231</td>\n",
       "      <td>0.388151</td>\n",
       "      <td>1.330975</td>\n",
       "      <td>-2.159078</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
       "0    1      1                           -0.082571   \n",
       "1    2      0                            0.343019   \n",
       "2    3      0                            1.248603   \n",
       "3    4      1                            0.044844   \n",
       "4    5      1                           -1.067449   \n",
       "\n",
       "   glcm_InverseVariance_exponential2  \\\n",
       "0                          -1.467897   \n",
       "1                           1.377483   \n",
       "2                           0.698196   \n",
       "3                          -0.316359   \n",
       "4                           2.091546   \n",
       "\n",
       "   glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
       "0                                   -0.371897   \n",
       "1                                   -0.326643   \n",
       "2                                   -0.326643   \n",
       "3                                   -1.180298   \n",
       "4                                    0.837405   \n",
       "\n",
       "   glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
       "0                                  -0.403232   \n",
       "1                                   2.612101   \n",
       "2                                  -0.536871   \n",
       "3                                   0.074876   \n",
       "4                                  -0.577231   \n",
       "\n",
       "   glcm_Correlation_log-sigma-3-0-mm-3D2  glszm_ZoneEntropy_exponential4  \\\n",
       "0                              -0.163733                       -0.537051   \n",
       "1                               0.663478                        0.046500   \n",
       "2                              -2.005267                        0.046500   \n",
       "3                               0.596528                       -0.746848   \n",
       "4                               0.388151                        1.330975   \n",
       "\n",
       "   firstorder_Skewness_logarithm2  \n",
       "0                       -0.044727  \n",
       "1                       -1.606117  \n",
       "2                       -0.960588  \n",
       "3                        1.090658  \n",
       "4                       -2.159078  "
      ]
     },
     "execution_count": 261,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# external test\n",
    "DSM_test_external = pd.read_csv(os.path.join(testdir, 'DSM_test_external.csv'))\n",
    "DSM3_extest_y = DSM_test_external['label']\n",
    "DSM3_extest_x = DSM_test_external.drop(Dtag_cols, axis=1)\n",
    "DSM3_extest_x = DSM3_extest_x\n",
    "DSM_test_external.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "8dad4683-72c3-4beb-b07b-de895d734557",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 300 candidates, totalling 1500 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4345/1605965934.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'balanced_accuracy'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                    )\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSM3_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDSM3_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbest_hp_now\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=5,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='balanced_accuracy'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(DSM3_train_x, DSM3_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c3cda5d-4b74-44eb-b6a1-48dda09e47ed",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "078d73a8-0246-4cbd-a60f-83c657ab9758",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 243 candidates, totalling 729 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4345/1603565093.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m                                                \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'neg_log_loss'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m                                               )\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mrandom_forest_model_test_2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDSM3_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mDSM3_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0mbest_hp_now_2\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_2_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1390\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m         \u001b[0;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1392\u001b[0;31m         \u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1393\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1394\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[150,200,250],\n",
    "                          'max_features':[2,3,4],\n",
    "                          'max_depth':[10, 20, 30],\n",
    "                          'min_samples_split':[8,10,12], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8,16]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=3,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               #scoring='balanced_accuracy'\n",
    "                                               scoring='neg_log_loss'\n",
    "                                              )\n",
    "random_forest_model_test_2_random.fit(DSM3_train_x, DSM3_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "b9ff2997-6d32-477a-9733-a8e0668ea88c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'max_depth': 25,\n",
      " 'max_features': 3,\n",
      " 'min_samples_leaf': 16,\n",
      " 'min_samples_split': 8,\n",
      " 'n_estimators': 160}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[100,150,160],\n",
    "                          'max_features':[3,4],\n",
    "                          'max_depth':[20,25],\n",
    "                          'min_samples_split':[6,7,8], # Greater than 1\n",
    "                          'min_samples_leaf':[8,16]\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='balanced_accuracy')\n",
    "random_forest_model_test_3_random.fit(DSM3_train_x, DSM3_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f396b3-7787-498c-aac1-6d03f86df130",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "5885566f-9461-4348-9ef5-f6e3975aed75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6857142857142857\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_DSM3.model']"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "DSM3=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = DSM3.score(DSM3_test_x, DSM3_test_y)\n",
    "print(score)\n",
    "joblib.dump(DSM3, os.path.join(modeldir, DSM3_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c8828-742e-43f0-8b47-58f1bcfeb0e1",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "4d503867-2025-43b5-b5da-7c8a0521bfe3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6857142857142857,\n",
       " 'recall': 0.782608695652174,\n",
       " 'precision': 0.75,\n",
       " 'f1': 0.7659574468085107,\n",
       " 'auc': 0.720108695652174,\n",
       " 'specificity': 0.5}"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, DSM3_model)) \n",
    "predict_label = model_forest.predict(DSM3_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(DSM3_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = DSM3_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "695f4c46-a980-47dc-9fc7-73edc92e2dec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.6444444444444445,\n",
       " 'recall': 0.6923076923076923,\n",
       " 'precision': 0.6923076923076923,\n",
       " 'f1': 0.6923076923076923,\n",
       " 'auc': 0.6153846153846154,\n",
       " 'specificity': 0.5789473684210527}"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model= joblib.load(os.path.join(modeldir, DSM3_model)) \n",
    "predict_label = model.predict(DSM3_extest_x) #预测的标签\n",
    "predict_score = model.predict_proba(DSM3_extest_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = DSM3_extest_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a03d314-82f9-46c6-993d-7ba3b9e4870b",
   "metadata": {},
   "source": [
    "### ASM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "d3d182e7-7df2-45b4-b46f-6714c73f87dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the ASM features.\n",
    "Atag_cols = ['pid', 'label']\n",
    "ASM_train = pd.read_csv(os.path.join(traindir, 'ASM_mrmr_feas.csv')) \n",
    "ASM_test = pd.read_csv(os.path.join(testdir, 'ASM_test.csv')) \n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "ASM_train = ASM_train.sample(frac=1.0, random_state=random_state) \n",
    "ASM_train_y = ASM_train['label'] \n",
    "ASM_train_x = ASM_train.drop(Atag_cols, axis=1) \n",
    "ASM_train_x = standardscaler.fit_transform(ASM_train_x) \n",
    "# Test data\n",
    "ASM_test = ASM_test.sample(frac=1.0, random_state=random_state)\n",
    "ASM_test_y = ASM_test['label']\n",
    "ASM_test_x =ASM_test.drop(Dtag_cols, axis=1)\n",
    "ASM_test_x = standardscaler.fit_transform(ASM_test_x)\n",
    "\n",
    "ASM_model = f'RandomForest_ASM.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "61647f6c-ca2f-4918-8257-b3d2a4764a87",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 300 candidates, totalling 1200 fits\n",
      "{'max_depth': 220,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 4,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 150}\n"
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b3c8206-278f-4770-9b58-d3101a9022ef",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7a544583-99e6-4009-846c-8bb284eec697",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 54 candidates, totalling 216 fits\n",
      "{'max_depth': 200,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 200}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[100, 150, 200],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[200, 220, 300],\n",
    "                          'min_samples_split':[4,5,6], # Greater than 1\n",
    "                          'min_samples_leaf':[4,8],\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='roc_auc')\n",
    "random_forest_model_test_2_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "e8b01d55-d717-47d6-b75d-f46d9ac28398",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "{'max_depth': 200,\n",
      " 'max_features': 'auto',\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 5,\n",
      " 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[200, 300],\n",
    "                          'max_features':['auto'],\n",
    "                          'max_depth':[200],\n",
    "                          'min_samples_split':[5], # Greater than 1\n",
    "                          'min_samples_leaf':[8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='accuracy')\n",
    "random_forest_model_test_3_random.fit(ASM_train_x, ASM_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29e8f59e-cc7d-4ae1-9611-fd154c29842b",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "f55aa9f9-3c82-48f4-9aa5-2174e3c0b2cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7571428571428571\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_ASM.model']"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "ASM=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = ASM.score(ASM_test_x, ASM_test_y)\n",
    "print(score)\n",
    "joblib.dump(ASM, os.path.join(modeldir, ASM_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc9dc6f-a068-46ca-a5dd-0c6ca78a6fe0",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "39198ee9-61c6-4023-9459-97dae3dc5325",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7571428571428571,\n",
       " 'recall': 0.9565217391304348,\n",
       " 'precision': 0.7457627118644068,\n",
       " 'f1': 0.8380952380952381,\n",
       " 'auc': 0.6838768115942029,\n",
       " 'specificity': 0.375}"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, ASM_model)) \n",
    "predict_label = model_forest.predict(ASM_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(ASM_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = ASM_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d2feac5-11c2-4023-b0ba-b8285bd86e1e",
   "metadata": {},
   "source": [
    "### Clinical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "40f9bcfb-41e8-424e-81be-881e9b01b426",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Clinical features.\n",
    "Atag_cols = ['pid', 'label']\n",
    "Clinical_train = pd.read_csv(os.path.join(traindir, 'clinical_lasso_sel.csv')) \n",
    "Clinical_test = pd.read_csv(os.path.join(testdir, 'clinical_test.csv')) \n",
    "# Train data\n",
    "standardscaler = StandardScaler()\n",
    "Clinical_train = Clinical_train.sample(frac=1.0, random_state=random_state) \n",
    "Clinical_train_y = Clinical_train['label'] \n",
    "Clinical_train_x = Clinical_train.drop(Atag_cols, axis=1) \n",
    "#Clinical_train_x = standardscaler.fit_transform(Clinical_train_x) \n",
    "# Test data\n",
    "#Clinical_test = Clinical_test.sample(frac=1.0, random_state=random_state)\n",
    "Clinical_test_y = np.array(Clinical_test['label'])\n",
    "Clinical_test_x = np.array(Clinical_test.drop(Dtag_cols, axis=1))\n",
    "#Clinical_test_x = standardscaler.fit_transform(Clinical_test_x)\n",
    "\n",
    "Clinical_model = f'RandomForest_Clinical.model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "ed8741fe-8749-4ea7-8840-0eafa1f2cc6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       mass_feature  NLR  diaphram_nodule  CA125  parenchymal_organs  HE4  \\\n",
      "label                                                                       \n",
      "0                55   55               55     55                  55   55   \n",
      "1                55   55               55     55                  55   55   \n",
      "\n",
      "       ascites_amount  relationship_on_T1_dual_echo_images  \\\n",
      "label                                                        \n",
      "0                  55                                   55   \n",
      "1                  55                                   55   \n",
      "\n",
      "       peritoneum_mesentery_nodules  LDH  \n",
      "label                                     \n",
      "0                                55   55  \n",
      "1                                55   55  \n"
     ]
    }
   ],
   "source": [
    "# 过采样\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.over_sampling import BorderlineSMOTE\n",
    "from imblearn.over_sampling import ADASYN \n",
    "from imblearn.under_sampling import TomekLinks\n",
    "from imblearn.under_sampling import ClusterCentroids \n",
    "Clinical_train = Clinical_train.sample(frac=1.0, random_state=123)\n",
    "Clinical_train = Clinical_train.drop(['pid'], axis=1)\n",
    "train_X, train_Y = Clinical_train.loc[:, Clinical_train.columns != 'label'], Clinical_train.loc[:, Clinical_train.columns == 'label']\n",
    "\n",
    "smote = SMOTE(k_neighbors=3, random_state=2022)\n",
    "X_smote, Y_smote = smote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "bsmote = BorderlineSMOTE(k_neighbors=4, random_state=2022)\n",
    "X_smote, Y_smote = bsmote.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "adasyn = ADASYN(n_neighbors=3, random_state=42)\n",
    "X_smote, Y_smote = adasyn.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "tl = TomekLinks()\n",
    "X_smote, Y_smote = tl.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "cc = ClusterCentroids(random_state=42)\n",
    "X_smote, Y_smote = cc.fit_resample(train_X, train_Y)\n",
    "df_smote = pd.concat([X_smote, Y_smote], axis=1)\n",
    "Clinical_train_x = np.array(df_smote.drop(['label'], axis=1))\n",
    "Clinical_train_y = np.array(df_smote['label'].to_list())\n",
    "\n",
    "print(df_smote.groupby('label').count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "90e858ce-9ecd-44be-97d3-f0c263d1ad43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 300 candidates, totalling 1200 fits\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_4345/1230416873.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     29\u001b[0m                                                    \u001b[0mscoring\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roc_auc'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                    )\n\u001b[0;32m---> 31\u001b[0;31m \u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mClinical_train_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClinical_train_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0mbest_hp_now\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrandom_forest_model_test_random\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_params_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    889\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 891\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0;31m# multimetric is determined here because in the case of a callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[0;34m(self, evaluate_candidates)\u001b[0m\n\u001b[1;32m   1766\u001b[0m         evaluate_candidates(\n\u001b[1;32m   1767\u001b[0m             ParameterSampler(\n\u001b[0;32m-> 1768\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam_distributions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_iter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1769\u001b[0m             )\n\u001b[1;32m   1770\u001b[0m         )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[0;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[1;32m    849\u001b[0m                     )\n\u001b[1;32m    850\u001b[0m                     for (cand_idx, parameters), (split_idx, (train, test)) in product(\n\u001b[0;32m--> 851\u001b[0;31m                         \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    852\u001b[0m                     )\n\u001b[1;32m    853\u001b[0m                 )\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1054\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1055\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1056\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1057\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1058\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    933\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    934\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 935\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    936\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mwrap_future_result\u001b[0;34m(future, timeout)\u001b[0m\n\u001b[1;32m    540\u001b[0m         AsyncResults.get from multiprocessing.\"\"\"\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfuture\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCfTimeoutError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/concurrent/futures/_base.py\u001b[0m in \u001b[0;36mresult\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    428\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    429\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 430\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_condition\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    431\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_state\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mCANCELLED\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mCANCELLED_AND_NOTIFIED\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/Chongfu1/lib/python3.7/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 296\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    297\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Search optimal hyperparameter\n",
    "random_seed=44\n",
    "random_forest_seed=np.random.randint(low=1,high=230)\n",
    "n_estimators_range=[int(x) for x in np.linspace(start=50,stop=3000,num=60)]\n",
    "max_features_range=['auto','sqrt']\n",
    "max_depth_range=[int(x) for x in np.linspace(10,500,num=50)]\n",
    "max_depth_range.append(None)\n",
    "min_samples_split_range=[2,5,10]\n",
    "min_samples_leaf_range=[1,2,4,8]\n",
    "bootstrap_range=[True,False]\n",
    "\n",
    "random_forest_hp_range={'n_estimators':n_estimators_range,\n",
    "                        'max_features':max_features_range,\n",
    "                        'max_depth':max_depth_range,\n",
    "                        'min_samples_split':min_samples_split_range,\n",
    "                        'min_samples_leaf':min_samples_leaf_range\n",
    "                        # 'bootstrap':bootstrap_range\n",
    "                        }\n",
    "\n",
    "# Random search\n",
    "random_forest_model_test_base=RandomForestClassifier()\n",
    "random_forest_model_test_random=RandomizedSearchCV(estimator=random_forest_model_test_base,\n",
    "                                                   param_distributions=random_forest_hp_range,\n",
    "                                                   n_iter=300,\n",
    "                                                   n_jobs=-1,\n",
    "                                                   cv=4,\n",
    "                                                   verbose=1,\n",
    "                                                   random_state=random_forest_seed,\n",
    "                                                   scoring='roc_auc'\n",
    "                                                   )\n",
    "random_forest_model_test_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now=random_forest_model_test_random.best_params_\n",
    "pprint(best_hp_now)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c996575d-fed8-46ea-b547-685ddddb2b85",
   "metadata": {},
   "source": [
    "#### 超参数遍历匹配择优\n",
    "+ 依据上述所得到的随机最优匹配结果，进行遍历全部组合的匹配择优。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "cee04782-1eb3-484e-9ddf-47ebbd00953d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 4 folds for each of 243 candidates, totalling 972 fits\n",
      "{'max_depth': 30,\n",
      " 'max_features': 5,\n",
      " 'min_samples_leaf': 2,\n",
      " 'min_samples_split': 3,\n",
      " 'n_estimators': 40}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_2={'n_estimators':[40, 50, 60],\n",
    "                          'max_features':[3,4,5],\n",
    "                          'max_depth':[30, 40, 50],\n",
    "                          'min_samples_split':[2,3,4], # Greater than 1\n",
    "                          'min_samples_leaf':[1, 2, 3],\n",
    "                          }\n",
    "random_forest_model_test_2_base=RandomForestClassifier()\n",
    "random_forest_model_test_2_random=GridSearchCV(estimator=random_forest_model_test_2_base,\n",
    "                                               param_grid=random_forest_hp_range_2,\n",
    "                                               cv=4,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='balanced_accuracy')\n",
    "random_forest_model_test_2_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now_2=random_forest_model_test_2_random.best_params_\n",
    "pprint(best_hp_now_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "2e11147f-0885-46be-b70a-e32fb0189b0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 72 candidates, totalling 360 fits\n",
      "{'max_depth': 30,\n",
      " 'max_features': 6,\n",
      " 'min_samples_leaf': 8,\n",
      " 'min_samples_split': 3,\n",
      " 'n_estimators': 30}\n"
     ]
    }
   ],
   "source": [
    "# Grid Search\n",
    "\n",
    "random_forest_hp_range_3={'n_estimators':[30,40],\n",
    "                          'max_features':[5,6],\n",
    "                          'max_depth':[20,30],\n",
    "                          'min_samples_split':[3,4,5], # Greater than 1\n",
    "                          'min_samples_leaf':[2,4,8]\n",
    "                          # 'bootstrap':bootstrap_range\n",
    "                          }\n",
    "random_forest_model_test_3_base=RandomForestClassifier()\n",
    "random_forest_model_test_3_random=GridSearchCV(estimator=random_forest_model_test_3_base,\n",
    "                                               param_grid=random_forest_hp_range_3,\n",
    "                                               cv=5,\n",
    "                                               verbose=1,\n",
    "                                               n_jobs=-1,\n",
    "                                               scoring='balanced_accuracy')\n",
    "random_forest_model_test_3_random.fit(Clinical_train_x, Clinical_train_y)\n",
    "\n",
    "best_hp_now_3=random_forest_model_test_3_random.best_params_\n",
    "pprint(best_hp_now_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df164134-9ca4-4d9b-8db7-50835bf7bc8e",
   "metadata": {},
   "source": [
    "#### Build (select) and save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "4a8f56be-3db5-4054-892f-53f31438c56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7428571428571429\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/media/tx-deepocean/Data/2022/chongfu1/Model/Train/Model/RandomForest_Clinical.model']"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build RF regression model with optimal hyperparameters\n",
    "Clinical=random_forest_model_test_3_random.best_estimator_\n",
    "# Predict test set data\n",
    "score = Clinical.score(Clinical_test_x, Clinical_test_y)\n",
    "print(score)\n",
    "joblib.dump(Clinical, os.path.join(modeldir, Clinical_model))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ac175e8-818e-4520-b9a2-4e8371d39c27",
   "metadata": {},
   "source": [
    "#### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "fc6b6e73-41db-4357-ac1b-196a0cdfe89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.7428571428571429,\n",
       " 'recall': 0.7608695652173914,\n",
       " 'precision': 0.8333333333333334,\n",
       " 'f1': 0.7954545454545455,\n",
       " 'auc': 0.8740942028985507,\n",
       " 'specificity': 0.7083333333333334}"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_forest = joblib.load(os.path.join(modeldir, Clinical_model)) \n",
    "predict_label = model_forest.predict(Clinical_test_x) #预测的标签\n",
    "predict_score = model_forest.predict_proba(Clinical_test_x)#得到标签0 (y_predict[:,0])和1 (y_predict[:,1])对应的概率\n",
    "label = Clinical_test_y  #真实标签\n",
    "eva_dic = classification_evaluation(label, predict_label, predict_score[:,1])\n",
    "eva_dic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75821c98-e297-412d-aabb-734e59032b76",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chongfu1",
   "language": "python",
   "name": "chongfu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

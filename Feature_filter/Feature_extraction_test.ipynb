{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9a4a8892-8ff9-4c5f-99b2-37c853f8456e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2d56e7d3-25e9-42de-bc1f-fbc7ed260a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wprint(info, style=0):\n",
    "    '''\n",
    "    :description: Information print with separator.\n",
    "    :param info: 'str', The information which want to print. \n",
    "    :param style: 'int', 0: Only one line info.\n",
    "    '''\n",
    "    if len(info) < 57:\n",
    "        tot_len = 60\n",
    "    elif len(info) < 77:\n",
    "        tot_len = 80\n",
    "    else:\n",
    "        tot_len = len(info)+6\n",
    "    space_len = (tot_len - len(info) - 6) // 2\n",
    "    print('='*tot_len)\n",
    "    print('=',' '*space_len, f'\\033[1;97;95m{info}\\033[0m', ' '*(tot_len-space_len-6-len(info)),'=')\n",
    "    print('='*tot_len)\n",
    "# 缺失值大于cut,则丢弃此列\n",
    "def drop_col(df, cutoff=0.5):\n",
    "    n = len(df)\n",
    "    for col_name in df.columns:\n",
    "        cnt = df[col_name].isnull().sum()\n",
    "        if (float(cnt) / n) > cutoff:\n",
    "            df.drop([col_name], axis=1, inplace=True)\n",
    "    return df\n",
    "\n",
    "def features_preprocess(df):\n",
    "    # 去除重复项\n",
    "    df = df.drop_duplicates()\n",
    "    # 丢掉缺失值比例超过50%的列\n",
    "    # df = drop_col(df)\n",
    "    # 用众数填充缺失值\n",
    "    #most_frequency = pd.Series(df.value_counts().index[0], index=df.columns)\n",
    "    # 用中位数填充缺失值\n",
    "    most_frequency = df.median()\n",
    "    #most_frequency = 0.\n",
    "    df = df.fillna(most_frequency)\n",
    "    return df\n",
    "\n",
    "def features_norm(df):\n",
    "    # 标准化\n",
    "    scale_features = list(df.select_dtypes(include=[float]))\n",
    "    ss = StandardScaler()\n",
    "    df[scale_features] = ss.fit_transform(df[scale_features])\n",
    "    return df\n",
    "\n",
    "# Add suffix for the colunms' name for the df.\n",
    "def feas_name_addsux(df, sux, exclude_columns=[]):\n",
    "    newcolumn = [name+str(sux) if name not in exclude_columns else name for name in list(df.columns) ]\n",
    "    df_copy = df.copy()\n",
    "    df_copy.columns=newcolumn\n",
    "    return df_copy\n",
    "\n",
    "def df_parallel_fusion(df_list, series_index, pid='pid', *nonfeas):\n",
    "    # The list which are not features' columns\n",
    "    no_feas_list = list(nonfeas)+[series_index, pid]\n",
    "    # Chage name for the df.columns.\n",
    "    df_list1 = [feas_name_addsux(df, str(df.at[0, series_index]), no_feas_list) for df in df_list]\n",
    "    # Remain the 'pid' for the first df. \n",
    "    df_fusion = df_list1[0].drop(list(nonfeas)+[series_index], axis=1)\n",
    "    for i in range(len(df_list)-1):\n",
    "        feas_list = [col for col in list(df_list1[i+1]) if col not in list(nonfeas)+[series_index]]\n",
    "        df_fusion = pd.merge(df_fusion, df_list1[i+1][feas_list], on=pid, how='inner')\n",
    "    return df_fusion\n",
    "\n",
    "# According to the index('str'), to select the df1[add_list] to concate with df.\n",
    "def df_added(df, df1, index, add_cols, how='inner'):\n",
    "    cols_copy = add_cols.copy()\n",
    "    cols_copy.insert(0, index)\n",
    "    new_df1 = df1[cols_copy]\n",
    "    new_df = pd.merge(new_df1, df, on=index, how=how)  # 'inner' 表示只取交集\n",
    "    return new_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4423e5d9-ac47-4544-adda-d93201f2a765",
   "metadata": {},
   "source": [
    "## Internal test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "633230f9-2b74-4bc4-b5e6-8e735cc7e5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cwd = os.getcwd()\n",
    "traindir = os.path.join(cwd, 'Feas_data')\n",
    "datadir = os.path.join(cwd, 'Feas_data_test')\n",
    "random_state = 2022 # random seed\n",
    "sequence_id = [2, 3, 4]                 # The digital id to label T2, DWI, T1CE sequences.\n",
    "tag_cols = ['pid', 'image','series', 'mask', 'label']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78213b36-e2cd-4dda-b4b2-53be5fab4b8c",
   "metadata": {},
   "source": [
    "### SSM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b669dd21-5a64-41ea-90e9-cefe6d6e3167",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------Select the features in train data extractor ----------------------------------------\n",
    "df_slist = [pd.read_excel(os.path.join(datadir, 'test_feas_scale.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "            sequence_id]\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "# df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_lasso.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "            sequence_id]\n",
    "df_columns_list = [df.columns for df in df_train_slist]\n",
    "df_slist = [df[col] for df,col in zip(df_slist, df_columns_list)]\n",
    "df_slist = [features_norm(df) for df in df_slist]\n",
    "# Save and print information\n",
    "pwriter = pd.ExcelWriter(os.path.join(datadir, 'SSM_test.xlsx'))\n",
    "for seq_, df in enumerate(df_slist):\n",
    "    df.to_excel(pwriter, f'sequence{seq_ + 2}', index=False)\n",
    "pwriter.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645e154d-f47e-4866-9533-1b0ed83c8335",
   "metadata": {},
   "source": [
    "### DSM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "23d583c5-e644-4846-9cb6-7ed94c781ba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "=   \u001b[1;97;95m7, 7 and 10                 features for no_sequence 2, 3 and 4 fusion.\u001b[0m    =\n",
      "================================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>glszm_SmallAreaEmphasis_logarithm2</th>\n",
       "      <th>glcm_InverseVariance_exponential2</th>\n",
       "      <th>glszm_GrayLevelNonUniformity_wavelet-HHH2</th>\n",
       "      <th>firstorder_Skewness_logarithm2</th>\n",
       "      <th>glcm_Correlation_log-sigma-3-0-mm-3D2</th>\n",
       "      <th>glrlm_ShortRunLowGrayLevelEmphasis_square4</th>\n",
       "      <th>glszm_ZoneEntropy_exponential4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.142857</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1.015061e-16</td>\n",
       "      <td>-1.903239e-17</td>\n",
       "      <td>-1.586033e-17</td>\n",
       "      <td>4.758099e-18</td>\n",
       "      <td>4.282289e-17</td>\n",
       "      <td>5.471813e-17</td>\n",
       "      <td>6.344132e-17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69.343983</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.379121e+00</td>\n",
       "      <td>-1.768737e+00</td>\n",
       "      <td>-7.987017e-01</td>\n",
       "      <td>-4.015094e+00</td>\n",
       "      <td>-2.687189e+00</td>\n",
       "      <td>-9.998220e-01</td>\n",
       "      <td>-4.497317e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.858936e-01</td>\n",
       "      <td>-8.705739e-01</td>\n",
       "      <td>-6.908957e-01</td>\n",
       "      <td>-3.893325e-01</td>\n",
       "      <td>-6.817374e-01</td>\n",
       "      <td>-7.330122e-01</td>\n",
       "      <td>-2.639472e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.263628e-01</td>\n",
       "      <td>-1.191104e-02</td>\n",
       "      <td>-3.162051e-01</td>\n",
       "      <td>3.272211e-01</td>\n",
       "      <td>4.738335e-03</td>\n",
       "      <td>-2.858058e-01</td>\n",
       "      <td>3.237146e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.752702e-01</td>\n",
       "      <td>8.855897e-01</td>\n",
       "      <td>8.397974e-02</td>\n",
       "      <td>6.365412e-01</td>\n",
       "      <td>6.708849e-01</td>\n",
       "      <td>2.604686e-01</td>\n",
       "      <td>6.395031e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.019223e+00</td>\n",
       "      <td>1.769255e+00</td>\n",
       "      <td>3.661935e+00</td>\n",
       "      <td>1.356856e+00</td>\n",
       "      <td>2.011847e+00</td>\n",
       "      <td>3.674148e+00</td>\n",
       "      <td>1.032140e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pid      label  glszm_SmallAreaEmphasis_logarithm2  \\\n",
       "count   70.000000  70.000000                        7.000000e+01   \n",
       "mean   122.142857   0.657143                        1.015061e-16   \n",
       "std     69.343983   0.478091                        1.007220e+00   \n",
       "min      5.000000   0.000000                       -3.379121e+00   \n",
       "25%     66.250000   0.000000                       -4.858936e-01   \n",
       "50%    116.000000   1.000000                        1.263628e-01   \n",
       "75%    181.750000   1.000000                        5.752702e-01   \n",
       "max    233.000000   1.000000                        2.019223e+00   \n",
       "\n",
       "       glcm_InverseVariance_exponential2  \\\n",
       "count                       7.000000e+01   \n",
       "mean                       -1.903239e-17   \n",
       "std                         1.007220e+00   \n",
       "min                        -1.768737e+00   \n",
       "25%                        -8.705739e-01   \n",
       "50%                        -1.191104e-02   \n",
       "75%                         8.855897e-01   \n",
       "max                         1.769255e+00   \n",
       "\n",
       "       glszm_GrayLevelNonUniformity_wavelet-HHH2  \\\n",
       "count                               7.000000e+01   \n",
       "mean                               -1.586033e-17   \n",
       "std                                 1.007220e+00   \n",
       "min                                -7.987017e-01   \n",
       "25%                                -6.908957e-01   \n",
       "50%                                -3.162051e-01   \n",
       "75%                                 8.397974e-02   \n",
       "max                                 3.661935e+00   \n",
       "\n",
       "       firstorder_Skewness_logarithm2  glcm_Correlation_log-sigma-3-0-mm-3D2  \\\n",
       "count                    7.000000e+01                           7.000000e+01   \n",
       "mean                     4.758099e-18                           4.282289e-17   \n",
       "std                      1.007220e+00                           1.007220e+00   \n",
       "min                     -4.015094e+00                          -2.687189e+00   \n",
       "25%                     -3.893325e-01                          -6.817374e-01   \n",
       "50%                      3.272211e-01                           4.738335e-03   \n",
       "75%                      6.365412e-01                           6.708849e-01   \n",
       "max                      1.356856e+00                           2.011847e+00   \n",
       "\n",
       "       glrlm_ShortRunLowGrayLevelEmphasis_square4  \\\n",
       "count                                7.000000e+01   \n",
       "mean                                 5.471813e-17   \n",
       "std                                  1.007220e+00   \n",
       "min                                 -9.998220e-01   \n",
       "25%                                 -7.330122e-01   \n",
       "50%                                 -2.858058e-01   \n",
       "75%                                  2.604686e-01   \n",
       "max                                  3.674148e+00   \n",
       "\n",
       "       glszm_ZoneEntropy_exponential4  \n",
       "count                    7.000000e+01  \n",
       "mean                     6.344132e-17  \n",
       "std                      1.007220e+00  \n",
       "min                     -4.497317e+00  \n",
       "25%                     -2.639472e-01  \n",
       "50%                      3.237146e-01  \n",
       "75%                      6.395031e-01  \n",
       "max                      1.032140e+00  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_slist = [pd.read_excel(os.path.join(datadir, 'SSM_test.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]\n",
    "tag_df = df_slist[0][['pid', 'label']]\n",
    "\n",
    "## Any two sequence fusion.\n",
    "dfuse_list = []\n",
    "for i in range(len(df_slist)):\n",
    "    fuse_df_list = [df_slist[k] for k in range(len(df_slist)) if k != i]\n",
    "    fuse_df = df_parallel_fusion(fuse_df_list, 'series', *tag_cols)\n",
    "    fuse_df = pd.merge(tag_df, fuse_df, on='pid', how='inner')\n",
    "    dfuse_list.append(fuse_df)\n",
    "\n",
    "writer = pd.ExcelWriter(os.path.join(datadir, 'DSM_feas.xlsx'))\n",
    "for seq_, df in enumerate(dfuse_list):\n",
    "    df.to_excel(writer, f'no_sequence{seq_ + 2}', index=False)\n",
    "writer.save()\n",
    "info = f'{dfuse_list[0].shape[1]-2}, {dfuse_list[1].shape[1]-2} and {dfuse_list[2].shape[1]-2} \\\n",
    "                features for no_sequence 2, 3 and 4 fusion.'\n",
    "wprint(info)\n",
    "dfuse_list[1].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "92993677-5154-49d4-b31b-28efc6a22fd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 7, 7]\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------Select the features in train data extractor ----------------------------------------\n",
    "df_slist = [pd.read_excel(os.path.join(datadir, 'DSM_feas.xlsx'), sheet_name=f'no_sequence{num}') for num in\n",
    "            sequence_id]\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train_slist = [pd.read_excel(os.path.join(traindir, 'DSM_feas_mrmr_sel.xlsx'), sheet_name=f'no_sequence{num}') for num in\n",
    "            sequence_id]\n",
    "df_columns_list = [df.columns for df in df_train_slist]\n",
    "df_slist = [df[col] for df,col in zip(df_slist, df_columns_list)]\n",
    "df_slist = [features_norm(df) for df in df_slist]\n",
    "# Save and print information\n",
    "pwriter = pd.ExcelWriter(os.path.join(datadir, 'DSM_test.xlsx'))\n",
    "for seq_, df in enumerate(df_slist):\n",
    "    df.to_excel(pwriter, f'no_sequence{seq_ + 2}', index=False)\n",
    "pwriter.save()\n",
    "feas_num = [(df.shape[1]-2) for df in df_slist]\n",
    "print(feas_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830ffd7a-241f-4ed7-ae69-0a24a6c8058a",
   "metadata": {},
   "source": [
    "### ASM selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2932b4cb-d1f6-4ef0-aa8d-e9633bf8ea50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## All sequences fusion.\n",
    "df_slist = [pd.read_excel(os.path.join(datadir, 'SSM_test.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]\n",
    "df_label = df_slist[0][['pid', 'label']]\n",
    "afuse_df = df_parallel_fusion(df_slist, 'series', 'pid', 'mask', 'image','label')\n",
    "afuse_df = pd.merge(df_label, afuse_df, on='pid', how='inner')\n",
    "afuse_df = afuse_df.sample(frac=1.0, random_state=random_state)\n",
    "afuse_df.to_csv(os.path.join(datadir, 'ASM_feas.csv'), index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08530517-3aba-487a-be40-b41eb000973e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['pid', 'label', 'gldm_DependenceVariance_wavelet-LLH3',\n",
      "       'ngtdm_Contrast_wavelet-HHL3', 'glcm_Correlation_log-sigma-3-0-mm-3D2',\n",
      "       'glszm_ZoneEntropy_exponential4', 'glcm_InverseVariance_exponential2',\n",
      "       'glcm_Imc2_wavelet-HHH3', 'glszm_GrayLevelNonUniformity_wavelet-HHH2',\n",
      "       'glszm_SmallAreaEmphasis_logarithm2', 'glrlm_RunEntropy_exponential3',\n",
      "       'firstorder_Skewness_log-sigma-2-0-mm-3D3',\n",
      "       'glrlm_ShortRunLowGrayLevelEmphasis_square4'],\n",
      "      dtype='object')\n",
      "============================================================\n",
      "=                   \u001b[1;97;95m11 features selected\u001b[0m                   =\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(datadir, 'ASM_feas.csv'))\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train = pd.read_csv(os.path.join(traindir, 'ASM_mrmr_feas.csv'))\n",
    "df_columns = df_train.columns \n",
    "print(df_columns)\n",
    "df = df[df_columns] \n",
    "info = f'{df.shape[1]-2} features selected'\n",
    "wprint(info)\n",
    "df.to_csv(os.path.join(datadir, 'ASM_test.csv'), index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d54a5657-d702-4e94-ae0b-4c2add7f5073",
   "metadata": {},
   "source": [
    "### Clinical selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "96e1904d-a6d6-49e9-afe0-85db547f1d8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "=       \u001b[1;97;95mClinical features consistent with radiomics\u001b[0m        =\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>age</th>\n",
       "      <th>unilateral_or_bilateral</th>\n",
       "      <th>mass_feature</th>\n",
       "      <th>diaphram_nodule</th>\n",
       "      <th>relationship_on_T1_dual_echo_images</th>\n",
       "      <th>peritoneum_mesentery_nodules</th>\n",
       "      <th>parenchymal_organs</th>\n",
       "      <th>CA125</th>\n",
       "      <th>HE4</th>\n",
       "      <th>LDH</th>\n",
       "      <th>NLR</th>\n",
       "      <th>ASA</th>\n",
       "      <th>ascites_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.00000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.142857</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>1.300547e-16</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>2.528571</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>1.771429</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>9.278292e-17</td>\n",
       "      <td>-1.903239e-17</td>\n",
       "      <td>1.054712e-16</td>\n",
       "      <td>-2.438526e-16</td>\n",
       "      <td>2.257143</td>\n",
       "      <td>1.542857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69.343983</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>0.50361</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>0.473085</td>\n",
       "      <td>1.009684</td>\n",
       "      <td>0.366563</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>0.440215</td>\n",
       "      <td>0.501757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.242827e+00</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.093531e-01</td>\n",
       "      <td>-7.441307e-01</td>\n",
       "      <td>-1.227800e+00</td>\n",
       "      <td>-9.719123e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.449341e-01</td>\n",
       "      <td>1.00000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.778139e-01</td>\n",
       "      <td>-6.061668e-01</td>\n",
       "      <td>-5.697525e-01</td>\n",
       "      <td>-6.252849e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.832244e-01</td>\n",
       "      <td>1.50000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.223852e-01</td>\n",
       "      <td>-3.726124e-01</td>\n",
       "      <td>-3.745099e-01</td>\n",
       "      <td>-2.495805e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.167905e-01</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-9.257017e-02</td>\n",
       "      <td>6.368678e-03</td>\n",
       "      <td>1.813337e-01</td>\n",
       "      <td>6.261375e-02</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.250851e+00</td>\n",
       "      <td>2.00000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.801511e+00</td>\n",
       "      <td>4.676612e+00</td>\n",
       "      <td>4.500577e+00</td>\n",
       "      <td>5.265851e+00</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pid      label           age  unilateral_or_bilateral  \\\n",
       "count   70.000000  70.000000  7.000000e+01                 70.00000   \n",
       "mean   122.142857   0.657143  1.300547e-16                  1.50000   \n",
       "std     69.343983   0.478091  1.007220e+00                  0.50361   \n",
       "min      5.000000   0.000000 -2.242827e+00                  1.00000   \n",
       "25%     66.250000   0.000000 -7.449341e-01                  1.00000   \n",
       "50%    116.000000   1.000000 -1.832244e-01                  1.50000   \n",
       "75%    181.750000   1.000000  9.167905e-01                  2.00000   \n",
       "max    233.000000   1.000000  2.250851e+00                  2.00000   \n",
       "\n",
       "       mass_feature  diaphram_nodule  relationship_on_T1_dual_echo_images  \\\n",
       "count     70.000000        70.000000                            70.000000   \n",
       "mean       2.528571         0.328571                             1.771429   \n",
       "std        0.630652         0.473085                             1.009684   \n",
       "min        1.000000         0.000000                             0.000000   \n",
       "25%        2.000000         0.000000                             1.000000   \n",
       "50%        3.000000         0.000000                             2.000000   \n",
       "75%        3.000000         1.000000                             2.750000   \n",
       "max        3.000000         1.000000                             3.000000   \n",
       "\n",
       "       peritoneum_mesentery_nodules  parenchymal_organs         CA125  \\\n",
       "count                     70.000000           70.000000  7.000000e+01   \n",
       "mean                       0.842857            0.071429  9.278292e-17   \n",
       "std                        0.366563            0.259399  1.007220e+00   \n",
       "min                        0.000000            0.000000 -3.093531e-01   \n",
       "25%                        1.000000            0.000000 -2.778139e-01   \n",
       "50%                        1.000000            0.000000 -2.223852e-01   \n",
       "75%                        1.000000            0.000000 -9.257017e-02   \n",
       "max                        1.000000            1.000000  7.801511e+00   \n",
       "\n",
       "                HE4           LDH           NLR        ASA  ascites_amount  \n",
       "count  7.000000e+01  7.000000e+01  7.000000e+01  70.000000       70.000000  \n",
       "mean  -1.903239e-17  1.054712e-16 -2.438526e-16   2.257143        1.542857  \n",
       "std    1.007220e+00  1.007220e+00  1.007220e+00   0.440215        0.501757  \n",
       "min   -7.441307e-01 -1.227800e+00 -9.719123e-01   2.000000        1.000000  \n",
       "25%   -6.061668e-01 -5.697525e-01 -6.252849e-01   2.000000        1.000000  \n",
       "50%   -3.726124e-01 -3.745099e-01 -2.495805e-01   2.000000        2.000000  \n",
       "75%    6.368678e-03  1.813337e-01  6.261375e-02   2.750000        2.000000  \n",
       "max    4.676612e+00  4.500577e+00  5.265851e+00   3.000000        2.000000  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "=              \u001b[1;97;95mClinical features' number: 13\u001b[0m               =\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# 临床特征查看验证标签\n",
    "clinical_df = pd.read_csv('../DataPreprocess/dataset_info/clinical_data.csv')\n",
    "compare_list = pd.read_excel(os.path.join(datadir, 'test_feas_scale.xlsx'), sheet_name='sequence2')\n",
    "train_num = len(compare_list)\n",
    "clinical_df = df_added(clinical_df, compare_list, index='pid', add_cols=['label'], how='inner')\n",
    "consis_label_num =(clinical_df['label_x']==clinical_df['label_y']).sum()\n",
    "if consis_label_num == train_num:\n",
    "    wprint('Clinical features consistent with radiomics')\n",
    "else:\n",
    "    wprint('Clinical features not consistent with radiomics, please cheak!!!')\n",
    "clinical_df.insert(1, 'label', clinical_df['label_x'])\n",
    "clinical_df = clinical_df.drop(['label_x', 'label_y'], axis=1)\n",
    "#clinical_df['mass_feature'] = clinical_df['mass_feature'].astype(float)\n",
    "clinical_df = features_preprocess(clinical_df)\n",
    "clinical_df = features_norm(clinical_df)\n",
    "clinical_df.to_csv(os.path.join(datadir, 'clinical_test_feas.csv'), index=0)\n",
    "info = f'Clinical features\\' number: {clinical_df.shape[1]-2}'\n",
    "clinical_df.describe()\n",
    "wprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e67b7ac9-9271-461a-b7aa-4ece401838db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "=                   \u001b[1;97;95m10 features selected\u001b[0m                   =\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>mass_feature</th>\n",
       "      <th>NLR</th>\n",
       "      <th>diaphram_nodule</th>\n",
       "      <th>CA125</th>\n",
       "      <th>parenchymal_organs</th>\n",
       "      <th>HE4</th>\n",
       "      <th>ascites_amount</th>\n",
       "      <th>relationship_on_T1_dual_echo_images</th>\n",
       "      <th>peritoneum_mesentery_nodules</th>\n",
       "      <th>LDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>1.580000e+02</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>1.580000e+02</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>158.000000</td>\n",
       "      <td>1.580000e+02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>116.550633</td>\n",
       "      <td>0.651899</td>\n",
       "      <td>2.329114</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.253165</td>\n",
       "      <td>9.837419e-18</td>\n",
       "      <td>0.069620</td>\n",
       "      <td>-5.621382e-18</td>\n",
       "      <td>1.626582</td>\n",
       "      <td>1.740506</td>\n",
       "      <td>0.721519</td>\n",
       "      <td>5.621382e-18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>68.790881</td>\n",
       "      <td>0.477883</td>\n",
       "      <td>0.785563</td>\n",
       "      <td>1.003180</td>\n",
       "      <td>0.436207</td>\n",
       "      <td>1.003180e+00</td>\n",
       "      <td>0.255315</td>\n",
       "      <td>1.003180e+00</td>\n",
       "      <td>0.485250</td>\n",
       "      <td>1.059866</td>\n",
       "      <td>0.449677</td>\n",
       "      <td>1.003180e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.444844</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.226793e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.885402e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.202434e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>53.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-0.702642</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.357474e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4.928630e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-5.212775e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>118.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-0.315323</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.537746e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.028820e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.258107e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>175.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.435465</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>1.141483e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.015706e-02</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.238642e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>235.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.546197</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>8.508225e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.831249e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.296381e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pid       label  mass_feature         NLR  diaphram_nodule  \\\n",
       "count  158.000000  158.000000    158.000000  158.000000       158.000000   \n",
       "mean   116.550633    0.651899      2.329114    0.000000         0.253165   \n",
       "std     68.790881    0.477883      0.785563    1.003180         0.436207   \n",
       "min      1.000000    0.000000      1.000000   -1.444844         0.000000   \n",
       "25%     53.250000    0.000000      2.000000   -0.702642         0.000000   \n",
       "50%    118.500000    1.000000      3.000000   -0.315323         0.000000   \n",
       "75%    175.750000    1.000000      3.000000    0.435465         0.750000   \n",
       "max    235.000000    1.000000      3.000000    4.546197         1.000000   \n",
       "\n",
       "              CA125  parenchymal_organs           HE4  ascites_amount  \\\n",
       "count  1.580000e+02          158.000000  1.580000e+02      158.000000   \n",
       "mean   9.837419e-18            0.069620 -5.621382e-18        1.626582   \n",
       "std    1.003180e+00            0.255315  1.003180e+00        0.485250   \n",
       "min   -6.226793e-01            0.000000 -5.885402e-01        1.000000   \n",
       "25%   -5.357474e-01            0.000000 -4.928630e-01        1.000000   \n",
       "50%   -3.537746e-01            0.000000 -3.028820e-01        2.000000   \n",
       "75%    1.141483e-01            0.000000  3.015706e-02        2.000000   \n",
       "max    8.508225e+00            1.000000  6.831249e+00        2.000000   \n",
       "\n",
       "       relationship_on_T1_dual_echo_images  peritoneum_mesentery_nodules  \\\n",
       "count                           158.000000                    158.000000   \n",
       "mean                              1.740506                      0.721519   \n",
       "std                               1.059866                      0.449677   \n",
       "min                               0.000000                      0.000000   \n",
       "25%                               1.000000                      0.000000   \n",
       "50%                               2.000000                      1.000000   \n",
       "75%                               3.000000                      1.000000   \n",
       "max                               3.000000                      1.000000   \n",
       "\n",
       "                LDH  \n",
       "count  1.580000e+02  \n",
       "mean   5.621382e-18  \n",
       "std    1.003180e+00  \n",
       "min   -1.202434e+00  \n",
       "25%   -5.212775e-01  \n",
       "50%   -3.258107e-01  \n",
       "75%    1.238642e-01  \n",
       "max    7.296381e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>mass_feature</th>\n",
       "      <th>NLR</th>\n",
       "      <th>diaphram_nodule</th>\n",
       "      <th>CA125</th>\n",
       "      <th>parenchymal_organs</th>\n",
       "      <th>HE4</th>\n",
       "      <th>ascites_amount</th>\n",
       "      <th>relationship_on_T1_dual_echo_images</th>\n",
       "      <th>peritoneum_mesentery_nodules</th>\n",
       "      <th>LDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.317512</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.080240</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.653564</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.053828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.384848</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.063505</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.361334</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1.492248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.166941</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.229288</td>\n",
       "      <td>0</td>\n",
       "      <td>0.324561</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4.500577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>-0.368949</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.284774</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.682545</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.364549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1.565431</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.050291</td>\n",
       "      <td>0</td>\n",
       "      <td>0.562451</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1.336851</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  mass_feature       NLR  diaphram_nodule     CA125  \\\n",
       "0    5      1             2  1.317512                0 -0.080240   \n",
       "1    6      1             2  1.384848                0 -0.063505   \n",
       "2    7      1             3 -0.166941                0 -0.229288   \n",
       "3   17      1             3 -0.368949                0 -0.284774   \n",
       "4   19      1             2  1.565431                1 -0.050291   \n",
       "\n",
       "   parenchymal_organs       HE4  ascites_amount  \\\n",
       "0                   0 -0.653564               2   \n",
       "1                   0 -0.361334               2   \n",
       "2                   0  0.324561               2   \n",
       "3                   0 -0.682545               2   \n",
       "4                   0  0.562451               2   \n",
       "\n",
       "   relationship_on_T1_dual_echo_images  peritoneum_mesentery_nodules       LDH  \n",
       "0                                    0                             1  0.053828  \n",
       "1                                    2                             1  1.492248  \n",
       "2                                    3                             1  4.500577  \n",
       "3                                    2                             1 -0.364549  \n",
       "4                                    3                             1  1.336851  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>mass_feature</th>\n",
       "      <th>NLR</th>\n",
       "      <th>diaphram_nodule</th>\n",
       "      <th>CA125</th>\n",
       "      <th>parenchymal_organs</th>\n",
       "      <th>HE4</th>\n",
       "      <th>ascites_amount</th>\n",
       "      <th>relationship_on_T1_dual_echo_images</th>\n",
       "      <th>peritoneum_mesentery_nodules</th>\n",
       "      <th>LDH</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>70.000000</td>\n",
       "      <td>7.000000e+01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>122.142857</td>\n",
       "      <td>0.657143</td>\n",
       "      <td>2.528571</td>\n",
       "      <td>-2.298261e-16</td>\n",
       "      <td>0.328571</td>\n",
       "      <td>9.992007e-17</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>-3.172066e-17</td>\n",
       "      <td>1.542857</td>\n",
       "      <td>1.771429</td>\n",
       "      <td>0.842857</td>\n",
       "      <td>1.134014e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>69.343983</td>\n",
       "      <td>0.478091</td>\n",
       "      <td>0.630652</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>0.473085</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>0.259399</td>\n",
       "      <td>1.007220e+00</td>\n",
       "      <td>0.501757</td>\n",
       "      <td>1.009684</td>\n",
       "      <td>0.366563</td>\n",
       "      <td>1.007220e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.719123e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.093531e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.441307e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-1.227800e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>66.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>-6.252849e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.778139e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-6.061668e-01</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-5.697525e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>-2.495805e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-2.223852e-01</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-3.726124e-01</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-3.745099e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>181.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>6.261375e-02</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-9.257017e-02</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.368678e-03</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.813337e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>5.265851e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>7.801511e+00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.676612e+00</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>4.500577e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              pid      label  mass_feature           NLR  diaphram_nodule  \\\n",
       "count   70.000000  70.000000     70.000000  7.000000e+01        70.000000   \n",
       "mean   122.142857   0.657143      2.528571 -2.298261e-16         0.328571   \n",
       "std     69.343983   0.478091      0.630652  1.007220e+00         0.473085   \n",
       "min      5.000000   0.000000      1.000000 -9.719123e-01         0.000000   \n",
       "25%     66.250000   0.000000      2.000000 -6.252849e-01         0.000000   \n",
       "50%    116.000000   1.000000      3.000000 -2.495805e-01         0.000000   \n",
       "75%    181.750000   1.000000      3.000000  6.261375e-02         1.000000   \n",
       "max    233.000000   1.000000      3.000000  5.265851e+00         1.000000   \n",
       "\n",
       "              CA125  parenchymal_organs           HE4  ascites_amount  \\\n",
       "count  7.000000e+01           70.000000  7.000000e+01       70.000000   \n",
       "mean   9.992007e-17            0.071429 -3.172066e-17        1.542857   \n",
       "std    1.007220e+00            0.259399  1.007220e+00        0.501757   \n",
       "min   -3.093531e-01            0.000000 -7.441307e-01        1.000000   \n",
       "25%   -2.778139e-01            0.000000 -6.061668e-01        1.000000   \n",
       "50%   -2.223852e-01            0.000000 -3.726124e-01        2.000000   \n",
       "75%   -9.257017e-02            0.000000  6.368678e-03        2.000000   \n",
       "max    7.801511e+00            1.000000  4.676612e+00        2.000000   \n",
       "\n",
       "       relationship_on_T1_dual_echo_images  peritoneum_mesentery_nodules  \\\n",
       "count                            70.000000                     70.000000   \n",
       "mean                              1.771429                      0.842857   \n",
       "std                               1.009684                      0.366563   \n",
       "min                               0.000000                      0.000000   \n",
       "25%                               1.000000                      1.000000   \n",
       "50%                               2.000000                      1.000000   \n",
       "75%                               2.750000                      1.000000   \n",
       "max                               3.000000                      1.000000   \n",
       "\n",
       "                LDH  \n",
       "count  7.000000e+01  \n",
       "mean   1.134014e-16  \n",
       "std    1.007220e+00  \n",
       "min   -1.227800e+00  \n",
       "25%   -5.697525e-01  \n",
       "50%   -3.745099e-01  \n",
       "75%    1.813337e-01  \n",
       "max    4.500577e+00  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join(datadir, 'clinical_test_feas.csv'))\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train = pd.read_csv(os.path.join(traindir, 'clinical_lasso_sel.csv'))\n",
    "df_columns = df_train.columns \n",
    "df = df[df_columns] \n",
    "info = f'{df.shape[1]-2} features selected'\n",
    "wprint(info)\n",
    "df.to_csv(os.path.join(datadir, 'clinical_test.csv'), index=0)\n",
    "df_train.describe()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d3a9273-6213-4e7e-b723-90fda06619f3",
   "metadata": {},
   "source": [
    "## External test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "37adc693-f33c-45d1-bd5f-285b0013ce9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pid</th>\n",
       "      <th>label</th>\n",
       "      <th>series</th>\n",
       "      <th>RD</th>\n",
       "      <th>mask</th>\n",
       "      <th>image</th>\n",
       "      <th>shape_Elongation_original</th>\n",
       "      <th>shape_Flatness_original</th>\n",
       "      <th>shape_LeastAxisLength_original</th>\n",
       "      <th>shape_MajorAxisLength_original</th>\n",
       "      <th>...</th>\n",
       "      <th>glszm_SmallAreaHighGrayLevelEmphasis_exponential</th>\n",
       "      <th>glszm_SmallAreaLowGrayLevelEmphasis_exponential</th>\n",
       "      <th>glszm_ZoneEntropy_exponential</th>\n",
       "      <th>glszm_ZonePercentage_exponential</th>\n",
       "      <th>glszm_ZoneVariance_exponential</th>\n",
       "      <th>ngtdm_Busyness_exponential</th>\n",
       "      <th>ngtdm_Coarseness_exponential</th>\n",
       "      <th>ngtdm_Complexity_exponential</th>\n",
       "      <th>ngtdm_Contrast_exponential</th>\n",
       "      <th>ngtdm_Strength_exponential</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>R2</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>0.194100</td>\n",
       "      <td>0.035149</td>\n",
       "      <td>5.567816</td>\n",
       "      <td>158.405448</td>\n",
       "      <td>...</td>\n",
       "      <td>3.342207</td>\n",
       "      <td>0.099761</td>\n",
       "      <td>3.010434</td>\n",
       "      <td>0.006092</td>\n",
       "      <td>5.142215e+05</td>\n",
       "      <td>12.326277</td>\n",
       "      <td>0.013660</td>\n",
       "      <td>0.361439</td>\n",
       "      <td>0.000181</td>\n",
       "      <td>0.194880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>R2</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>0.837888</td>\n",
       "      <td>0.779085</td>\n",
       "      <td>24.473828</td>\n",
       "      <td>31.413538</td>\n",
       "      <td>...</td>\n",
       "      <td>4.816801</td>\n",
       "      <td>0.083049</td>\n",
       "      <td>3.574558</td>\n",
       "      <td>0.011355</td>\n",
       "      <td>1.499647e+05</td>\n",
       "      <td>36.426232</td>\n",
       "      <td>0.005033</td>\n",
       "      <td>1.421613</td>\n",
       "      <td>0.005755</td>\n",
       "      <td>0.056022</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>R0</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>0.113828</td>\n",
       "      <td>0.025387</td>\n",
       "      <td>27.517706</td>\n",
       "      <td>1083.946699</td>\n",
       "      <td>...</td>\n",
       "      <td>21.116616</td>\n",
       "      <td>0.057424</td>\n",
       "      <td>5.814968</td>\n",
       "      <td>0.014091</td>\n",
       "      <td>4.505141e+06</td>\n",
       "      <td>452.113424</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>97.446421</td>\n",
       "      <td>0.013427</td>\n",
       "      <td>0.010267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>R0</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>R0</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>/media/tx-deepocean/Data/2022/chongfu1/Dataset...</td>\n",
       "      <td>0.782079</td>\n",
       "      <td>0.417705</td>\n",
       "      <td>24.519569</td>\n",
       "      <td>58.700707</td>\n",
       "      <td>...</td>\n",
       "      <td>34.203468</td>\n",
       "      <td>0.046023</td>\n",
       "      <td>5.532083</td>\n",
       "      <td>0.067723</td>\n",
       "      <td>1.114655e+04</td>\n",
       "      <td>12.684849</td>\n",
       "      <td>0.001794</td>\n",
       "      <td>185.874065</td>\n",
       "      <td>0.045435</td>\n",
       "      <td>0.845809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 1460 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   pid  label  series  RD                                               mask  \\\n",
       "0    1      1       2  R2  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "1    1      1       4  R2  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "2    2      0       2  R0  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "3    2      0       4  R0  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "4    3      0       2  R0  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "\n",
       "                                               image  \\\n",
       "0  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "1  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "2  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "3  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "4  /media/tx-deepocean/Data/2022/chongfu1/Dataset...   \n",
       "\n",
       "   shape_Elongation_original  shape_Flatness_original  \\\n",
       "0                   0.194100                 0.035149   \n",
       "1                   0.837888                 0.779085   \n",
       "2                   0.113828                 0.025387   \n",
       "3                        NaN                      NaN   \n",
       "4                   0.782079                 0.417705   \n",
       "\n",
       "   shape_LeastAxisLength_original  shape_MajorAxisLength_original  ...  \\\n",
       "0                        5.567816                      158.405448  ...   \n",
       "1                       24.473828                       31.413538  ...   \n",
       "2                       27.517706                     1083.946699  ...   \n",
       "3                             NaN                             NaN  ...   \n",
       "4                       24.519569                       58.700707  ...   \n",
       "\n",
       "   glszm_SmallAreaHighGrayLevelEmphasis_exponential  \\\n",
       "0                                          3.342207   \n",
       "1                                          4.816801   \n",
       "2                                         21.116616   \n",
       "3                                               NaN   \n",
       "4                                         34.203468   \n",
       "\n",
       "   glszm_SmallAreaLowGrayLevelEmphasis_exponential  \\\n",
       "0                                         0.099761   \n",
       "1                                         0.083049   \n",
       "2                                         0.057424   \n",
       "3                                              NaN   \n",
       "4                                         0.046023   \n",
       "\n",
       "   glszm_ZoneEntropy_exponential  glszm_ZonePercentage_exponential  \\\n",
       "0                       3.010434                          0.006092   \n",
       "1                       3.574558                          0.011355   \n",
       "2                       5.814968                          0.014091   \n",
       "3                            NaN                               NaN   \n",
       "4                       5.532083                          0.067723   \n",
       "\n",
       "   glszm_ZoneVariance_exponential  ngtdm_Busyness_exponential  \\\n",
       "0                    5.142215e+05                   12.326277   \n",
       "1                    1.499647e+05                   36.426232   \n",
       "2                    4.505141e+06                  452.113424   \n",
       "3                             NaN                         NaN   \n",
       "4                    1.114655e+04                   12.684849   \n",
       "\n",
       "   ngtdm_Coarseness_exponential  ngtdm_Complexity_exponential  \\\n",
       "0                      0.013660                      0.361439   \n",
       "1                      0.005033                      1.421613   \n",
       "2                      0.000033                     97.446421   \n",
       "3                           NaN                           NaN   \n",
       "4                      0.001794                    185.874065   \n",
       "\n",
       "   ngtdm_Contrast_exponential  ngtdm_Strength_exponential  \n",
       "0                    0.000181                    0.194880  \n",
       "1                    0.005755                    0.056022  \n",
       "2                    0.013427                    0.010267  \n",
       "3                         NaN                         NaN  \n",
       "4                    0.045435                    0.845809  \n",
       "\n",
       "[5 rows x 1460 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n",
      "/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/ipykernel_launcher.py:34: FutureWarning: Dropping of nuisance columns in DataFrame reductions (with 'numeric_only=None') is deprecated; in a future version this will raise TypeError.  Select only valid columns before calling the reduction.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 1454)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20622/3270472338.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'series'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ex_df0 = ex_df[ex_df['label']==0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20622/3270472338.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mex_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'series'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mnum\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_preprocess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeatures_norm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mex_df_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort_values\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mascending\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mex_df_slist\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# ex_df0 = ex_df[ex_df['label']==0]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20622/2517336148.py\u001b[0m in \u001b[0;36mfeatures_norm\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0mscale_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_dtypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0mss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m     \u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale_features\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscale_features\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36mfit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    850\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    851\u001b[0m             \u001b[0;31m# fit method of arity 1 (unsupervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 852\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    853\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m             \u001b[0;31m# fit method of arity 2 (supervised transformation)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    804\u001b[0m         \u001b[0;31m# Reset internal state before fitting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    805\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 806\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    807\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    808\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/preprocessing/_data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"allow-nan\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 847\u001b[0;31m             \u001b[0mreset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfirst_call\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    848\u001b[0m         )\n\u001b[1;32m    849\u001b[0m         \u001b[0mn_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Validation should be done on X, y or both.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    565\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 566\u001b[0;31m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    567\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    568\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mno_val_y\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    806\u001b[0m                 \u001b[0;34m\"Found array with %d sample(s) (shape=%s) while a\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m                 \u001b[0;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 808\u001b[0;31m                 \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    809\u001b[0m             )\n\u001b[1;32m    810\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 1454)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "sequence_id1 = [2, 3, 4]\n",
    "ex_df = pd.read_csv('../DataPreprocess/dataset_info/external_feas_original.csv')\n",
    "# ex_df_na = ex_df[ex_df['shape_Elongation_original'].isna()]\n",
    "# nan_pid = ex_df_na['pid'].values\n",
    "# ex_df = ex_df[~ex_df['pid'].isin(nan_pid)]\n",
    "ex_df.head()\n",
    "# Select the test dataset\n",
    "ex_df = ex_df.drop(['RD'], axis=1)\n",
    "ex_df_slist = [ex_df[ex_df['series'] == num] for num in [2,3, 4]]\n",
    "ex_df_slist = [features_preprocess(df) for df in ex_df_slist]\n",
    "ex_df_slist = [features_norm(df) for df in ex_df_slist]\n",
    "ex_df_slist = [df.sort_values(['pid'], ascending=[True]) for df in ex_df_slist]\n",
    "# ex_df0 = ex_df[ex_df['label']==0]\n",
    "# ex_df1 = ex_df[ex_df['label']==1]\n",
    "\n",
    "# ex_df_slist = [ex_df0[ex_df0['series'] == num] for num in [2,4]]\n",
    "# ex_df_slist = [features_preprocess(df) for df in ex_df_slist]\n",
    "# ex_df_slist = [features_norm(df) for df in ex_df_slist]\n",
    "# ex_df_slist = [df.sort_values(['pid'], ascending=[True]) for df in ex_df_slist]\n",
    "# \n",
    "# ex_df_slist1 = [ex_df1[ex_df1['series'] == num] for num in [2,4]]\n",
    "# ex_df_slist1 = [features_preprocess(df) for df in ex_df_slist1]\n",
    "# ex_df_slist1 = [features_norm(df) for df in ex_df_slist1]\n",
    "# ex_df_slist1 = [df.sort_values(['pid'], ascending=[True]) for df in ex_df_slist1]\n",
    "\n",
    "# ex_df_slist = [pd.concat([df0,df1], axis=0) for df0, df1 in zip(ex_df_slist,ex_df_slist1)]\n",
    "\n",
    "# Save and print information\n",
    "pwriter = pd.ExcelWriter('./Feas_data_test/external_feas_scale.xlsx')\n",
    "for seq_, df in zip([2,3, 4],ex_df_slist):\n",
    "    df.to_excel(pwriter,f'sequence{seq_}', index=0)\n",
    "pwriter.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fdb784-d4f4-4853-a481-08da32528961",
   "metadata": {},
   "source": [
    "### SSM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d411eddb-7009-45e7-a56c-04e534cfde38",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'sequence3' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20622/1814743326.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ---------------------------------------Select the features in train data extractor ----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m df_slist = [pd.read_excel(os.path.join(datadir, 'external_feas_scale.xlsx'), sheet_name=f'sequence{num}') for num in\n\u001b[0;32m----> 3\u001b[0;31m             sequence_id]\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the train output files and get the extracted features' name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in\n",
      "\u001b[0;32m/tmp/ipykernel_20622/1814743326.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# ---------------------------------------Select the features in train data extractor ----------------------------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m df_slist = [pd.read_excel(os.path.join(datadir, 'external_feas_scale.xlsx'), sheet_name=f'sequence{num}') for num in\n\u001b[0m\u001b[1;32m      3\u001b[0m             sequence_id]\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Read the train output files and get the extracted features' name.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mconvert_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0mconvert_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m         )\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                 \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume an integer if not a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_if_bad_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mraise_if_bad_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_if_bad_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Worksheet named '{name}' not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     def parse(\n",
      "\u001b[0;31mValueError\u001b[0m: Worksheet named 'sequence3' not found"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------Select the features in train data extractor ----------------------------------------\n",
    "df_slist = [pd.read_excel(os.path.join(datadir, 'external_feas_scale.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "            sequence_id]\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_mrmr_sel.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "# df_train_slist = [pd.read_excel(os.path.join(traindir, 'feas_lasso.xlsx'), sheet_name=f'sequence{num}') for num in\n",
    "            sequence_id]\n",
    "df_columns_list = [df.columns for df in df_train_slist]\n",
    "df_slist = [df[col] for df,col in zip(df_slist, df_columns_list)]\n",
    "df_slist = [features_norm(df) for df in df_slist]\n",
    "# Save and print information\n",
    "pwriter = pd.ExcelWriter(os.path.join(datadir, 'SSM_test_external.xlsx'))\n",
    "for seq_, df in zip(sequence_id,df_slist):\n",
    "    df.to_excel(pwriter, f'sequence{seq_}', index=False)\n",
    "pwriter.save()\n",
    "print(sequence_id)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dfd25-9017-4862-b1cd-f90487fa3f21",
   "metadata": {},
   "source": [
    "### DSM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de95a6e4-71c8-4faf-a462-1d77eadfc6d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "=                   \u001b[1;97;95m7 features for DSM.\u001b[0m                    =\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "df_slist = [pd.read_excel(os.path.join(datadir, 'SSM_test_external.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id1]\n",
    "tag_df = df_slist[0][['pid', 'label']]\n",
    "\n",
    "## Any two sequence fusion.\n",
    "fuse_df = df_parallel_fusion(df_slist, 'series', *tag_cols)\n",
    "fuse_df = pd.merge(tag_df, fuse_df, on='pid', how='inner')\n",
    "\n",
    "fuse_df.to_csv(os.path.join(datadir, 'DSM_feas_external.csv'), index=0)\n",
    "info = f'{fuse_df.shape[1]-2} features for DSM.'\n",
    "wprint(info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5f716d63-c075-42c3-9630-3c6f81af4fd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "feas num is 7\n"
     ]
    }
   ],
   "source": [
    "# ---------------------------------------Select the features in train data extractor ----------------------------------------\n",
    "df_DSM = pd.read_csv(os.path.join(datadir, 'DSM_feas_external.csv'))\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train_slist = [pd.read_excel(os.path.join(traindir, 'DSM_feas_mrmr_sel.xlsx'), sheet_name=f'no_sequence{num}') for num in\n",
    "            sequence_id]\n",
    "df_columns_list = df_train_slist[1].columns \n",
    "df_DSM = df_DSM[df_columns_list]\n",
    "# Save and print information\n",
    "df_DSM.to_csv(os.path.join(datadir, 'DSM_test_external.csv'), index=0)\n",
    "print(f'feas num is {df_DSM.shape[1]-2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d0e52e8-5aa2-4840-b533-f572f7653a76",
   "metadata": {},
   "source": [
    "### ASM selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "181701ee-0833-435a-91c1-8956530fc13a",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Worksheet named 'sequence4' not found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20622/2042933592.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## All sequences fusion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SSM_test_external.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'sequence{num}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_slist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mafuse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_parallel_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_slist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'series'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mafuse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafuse_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20622/2042933592.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m## All sequences fusion.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf_slist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdatadir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'SSM_test_external.xlsx'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msheet_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34mf'sequence{num}'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msequence_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mdf_label\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_slist\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mafuse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf_parallel_fusion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_slist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'series'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mask'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'image'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mafuse_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mafuse_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'pid'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhow\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'inner'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[1;32m    393\u001b[0m             \u001b[0mskipfooter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mskipfooter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    394\u001b[0m             \u001b[0mconvert_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 395\u001b[0;31m             \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    396\u001b[0m         )\n\u001b[1;32m    397\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, converters, true_values, false_values, skiprows, nrows, na_values, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m   1290\u001b[0m             \u001b[0mconvert_float\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_float\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1291\u001b[0m             \u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmangle_dupe_cols\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1292\u001b[0;31m             \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1293\u001b[0m         )\n\u001b[1;32m   1294\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mparse\u001b[0;34m(self, sheet_name, header, names, index_col, usecols, squeeze, dtype, true_values, false_values, skiprows, nrows, na_values, verbose, parse_dates, date_parser, thousands, comment, skipfooter, convert_float, mangle_dupe_cols, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                 \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# assume an integer if not a string\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m                 \u001b[0msheet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_sheet_by_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0masheetname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_openpyxl.py\u001b[0m in \u001b[0;36mget_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    541\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraise_if_bad_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbook\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/media/tx-deepocean/Data/TX_wrapperenv/chongfu1/lib/python3.7/site-packages/pandas/io/excel/_base.py\u001b[0m in \u001b[0;36mraise_if_bad_sheet_by_name\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    472\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mraise_if_bad_sheet_by_name\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msheet_names\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Worksheet named '{name}' not found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     def parse(\n",
      "\u001b[0;31mValueError\u001b[0m: Worksheet named 'sequence4' not found"
     ]
    }
   ],
   "source": [
    "## All sequences fusion.\n",
    "df_slist = [pd.read_excel(os.path.join(datadir, 'SSM_test_external.xlsx'), sheet_name=f'sequence{num}') for num in sequence_id]\n",
    "df_label = df_slist[0][['pid', 'label']]\n",
    "afuse_df = df_parallel_fusion(df_slist, 'series', 'pid', 'mask', 'image','label')\n",
    "afuse_df = pd.merge(df_label, afuse_df, on='pid', how='inner')\n",
    "afuse_df = afuse_df.sample(frac=1.0, random_state=random_state)\n",
    "afuse_df.to_csv(os.path.join(datadir, 'ASM_feas.csv'), index=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c469bfed-0d9c-4bf0-a06b-ff3f2776284c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(datadir, 'ASM_feas.csv'))\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train = pd.read_csv(os.path.join(traindir, 'ASM_mrmr_feas.csv'))\n",
    "df_columns = df_train.columns \n",
    "print(df_columns)\n",
    "df = df[df_columns] \n",
    "info = f'{df.shape[1]-2} features selected'\n",
    "wprint(info)\n",
    "df.to_csv(os.path.join(datadir, 'ASM_test_external.csv'), index=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d848c40-ce0a-4fd9-adc5-943a7da07cc3",
   "metadata": {},
   "source": [
    "### Clinical selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f93b7528-66da-483d-b5b2-a89cedcd1b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 临床特征查看验证标签\n",
    "ex_clinical_df = pd.read_csv('../DataPreprocess/dataset_info/external_clinical.csv')\n",
    "compare_list = pd.read_excel(os.path.join(datadir, 'external_feas_scale.xlsx'), sheet_name='sequence2')\n",
    "train_num = len(compare_list)\n",
    "ex_clinical_df = df_added(ex_clinical_df, compare_list, index='pid', add_cols=['label'], how='inner')\n",
    "consis_label_num =(ex_clinical_df['label_x']==ex_clinical_df['label_y']).sum()\n",
    "if consis_label_num == train_num:\n",
    "    wprint('ex_clinical features consistent with radiomics')\n",
    "else:\n",
    "    wprint('ex_clinical features not consistent with radiomics, please cheak!!!')\n",
    "ex_clinical_df.insert(1, 'label', ex_clinical_df['label_x'])\n",
    "ex_clinical_df = ex_clinical_df.drop(['label_x', 'label_y'], axis=1)\n",
    "ex_clinical_df.to_csv(os.path.join(datadir, 'clinical_external_feas.csv'), index=0)\n",
    "info = f'ex_clinical features\\' number: {ex_clinical_df.shape[1]-2}'\n",
    "wprint(info)\n",
    "ex_clinical_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed862bc-5d21-4198-9695-8fbb24843701",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(os.path.join(datadir, 'clinical_external_feas.csv'))\n",
    "df['CA125'] = df['CA125'].astype(float)\n",
    "df['HE4'] = df['HE4'].astype(float)\n",
    "df = features_preprocess(df)\n",
    "df = features_norm(df)\n",
    "# Read the train output files and get the extracted features' name.\n",
    "df_train = pd.read_csv(os.path.join(traindir, 'clinical_lasso_sel.csv'))\n",
    "df_columns = df_train.columns \n",
    "df = df[df_columns] \n",
    "info = f'{df.shape[1]-2} features selected'\n",
    "wprint(info)\n",
    "df.to_csv(os.path.join(datadir, 'clinical_test_external.csv'), index=0)\n",
    "df.describe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c184cc-43a5-4793-82bd-a4b7c03afa10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f58ed9-7c80-402a-ab7f-539eec223d4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chongfu1",
   "language": "python",
   "name": "chongfu1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
